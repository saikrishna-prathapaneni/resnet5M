{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "           ResNet-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "             ReLU-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 56, 56]             128\n",
      "           ResNet-16           [-1, 64, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "           ResNet-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 28, 28]             256\n",
      "             ReLU-25          [-1, 128, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "           Conv2d-28          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "           ResNet-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "           Conv2d-34          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 28, 28]             256\n",
      "           ResNet-36          [-1, 128, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "             ReLU-39          [-1, 128, 28, 28]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "           ResNet-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "           ResNet-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "           ResNet-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-56          [-1, 128, 28, 28]             256\n",
      "             ReLU-57          [-1, 128, 28, 28]               0\n",
      "           Conv2d-58          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-59          [-1, 128, 28, 28]             256\n",
      "           ResNet-60          [-1, 128, 28, 28]               0\n",
      "           Conv2d-61          [-1, 512, 14, 14]         589,824\n",
      "      BatchNorm2d-62          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-63          [-1, 512, 14, 14]               0\n",
      "           Conv2d-64          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-65          [-1, 512, 14, 14]           1,024\n",
      "           Conv2d-66          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-67          [-1, 512, 14, 14]           1,024\n",
      "           ResNet-68          [-1, 512, 14, 14]               0\n",
      "AdaptiveAvgPool2d-69            [-1, 512, 1, 1]               0\n",
      "          Flatten-70                  [-1, 512]               0\n",
      "           Linear-71                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,961,610\n",
      "Trainable params: 4,961,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 82.70\n",
      "Params size (MB): 18.93\n",
      "Estimated Total Size (MB): 102.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, inchannels, outchannels, kernel_size=3, stride=1, skip=True):\n",
    "        super().__init__()\n",
    "        self.skip = skip\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(inchannels, outchannels, kernel_size=kernel_size, stride=stride, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannels, outchannels, kernel_size=kernel_size, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "           \n",
    "        )\n",
    "        if stride == 2 or inchannels != outchannels:\n",
    "            self.skip = False\n",
    "            self.skip_conv = nn.Conv2d(inchannels, outchannels, kernel_size=1, stride=stride,bias=False)\n",
    "            self.skip_bn = nn.BatchNorm2d(outchannels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if not self.skip:\n",
    "            out += self.skip_bn(self.skip_conv(x))\n",
    "        else:\n",
    "            out += x\n",
    "        out = F.relu(out.clone())\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,stride=2, padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        #self.resblock1 = ResNet(32, 32,stride=1)\n",
    "        #self.resblock2 = ResNet(64, 64,stride=1)\n",
    "        self.resblock3 = ResNet(64, 64,stride=1)\n",
    "        #self.resblock4=ResNet(64,64,stride=1)\n",
    "        #self.resblock5=ResNet(64,64,stride=1)\n",
    "        self.resblock6=ResNet(64,64,stride=1)\n",
    "        self.resblock7=ResNet(64,64,stride=1)\n",
    "        self.resblock8=ResNet(64,128,stride=2)\n",
    "        self.resblock9=ResNet(128,128,stride=1)\n",
    "        self.resblock10=ResNet(128,128,stride=1)\n",
    "        self.resblock11=ResNet(128,128,stride=1)\n",
    "        self.resblock12=ResNet(128,128,stride=1)\n",
    "        self.resblock13=ResNet(128,128,stride=1)\n",
    "        self.resblock14 =ResNet(128,512,stride=2)\n",
    "       #self.resblock15 =ResNet(512,512,stride=1)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.flat=nn.Flatten()\n",
    "        self.fc1= nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x.clone())\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.resblock1(x)\n",
    "        #x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        #x = self.resblock4(x)\n",
    "        #x = self.resblock5(x)\n",
    "        x = self.resblock6(x)\n",
    "        x = self.resblock7(x)\n",
    "        x = self.resblock8(x)\n",
    "        x = self.resblock9(x)\n",
    "        x = self.resblock10(x)\n",
    "        x = self.resblock11(x)\n",
    "        x = self.resblock12(x)\n",
    "        x = self.resblock13(x)\n",
    "        x= self.resblock14(x)\n",
    "        #x= self.resblock15(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x) \n",
    "     \n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNetF()\n",
    "model=model.cuda()\n",
    "random_matrix = torch.rand(1, 3, 224, 224).cuda()\n",
    "print(model.forward(random_matrix).shape)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity = 'relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def calculate_accuracy(y_pred, y): # calcualting the accuracy of the model\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device): # traing the model on with the images in iterator\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.train()\n",
    "   \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    lr_scheduler.step()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred= model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "train loss per epoch =>  0 1.6275636015645683 train acc per epoch=>  0.4059782609000535\n",
      "val loss per epoch =>  1.460706396193444 val acc per epoch => 0.4904074367088608 \n",
      "\n",
      "train loss per epoch =>  1 1.3072821275352517 train acc per epoch=>  0.5275695333090584\n",
      "val loss per epoch =>  1.2590239757223973 val acc per epoch => 0.5544897151898734 \n",
      "\n",
      "train loss per epoch =>  2 1.1546988305838213 train acc per epoch=>  0.5863251279077262\n",
      "val loss per epoch =>  1.4295406266103816 val acc per epoch => 0.5377768987341772 \n",
      "\n",
      "train loss per epoch =>  3 1.0520073469642484 train acc per epoch=>  0.6254355819024089\n",
      "val loss per epoch =>  1.1668469890763489 val acc per epoch => 0.6116495253164557 \n",
      "\n",
      "train loss per epoch =>  4 0.9723887138659387 train acc per epoch=>  0.654263906619128\n",
      "val loss per epoch =>  0.8883857900583292 val acc per epoch => 0.6930379746835443 \n",
      "\n",
      "train loss per epoch =>  5 0.912689870885571 train acc per epoch=>  0.6804707481733063\n",
      "val loss per epoch =>  0.8684370034857641 val acc per epoch => 0.694620253164557 \n",
      "\n",
      "train loss per epoch =>  6 0.8690917182456502 train acc per epoch=>  0.6942535166240409\n",
      "val loss per epoch =>  0.8684710664085195 val acc per epoch => 0.7023338607594937 \n",
      "\n",
      "train loss per epoch =>  7 0.8299574859611824 train acc per epoch=>  0.7092631075083448\n",
      "val loss per epoch =>  0.8271646039395393 val acc per epoch => 0.7165743670886076 \n",
      "\n",
      "train loss per epoch =>  8 0.7904466945496972 train acc per epoch=>  0.7217631074778564\n",
      "val loss per epoch =>  0.7949985876868043 val acc per epoch => 0.7217167721518988 \n",
      "\n",
      "train loss per epoch =>  9 0.7640224335443638 train acc per epoch=>  0.7315377237851662\n",
      "val loss per epoch =>  0.776617710348926 val acc per epoch => 0.7270569620253164 \n",
      "\n",
      "train loss per epoch =>  10 0.7352244356251738 train acc per epoch=>  0.7422794117342175\n",
      "val loss per epoch =>  0.7398507757277428 val acc per epoch => 0.7459454113924051 \n",
      "\n",
      "train loss per epoch =>  11 0.7177419345397169 train acc per epoch=>  0.7489809782608695\n",
      "val loss per epoch =>  0.6998482278630703 val acc per epoch => 0.7603837025316456 \n",
      "\n",
      "train loss per epoch =>  12 0.6985735217171252 train acc per epoch=>  0.7552229859639922\n",
      "val loss per epoch =>  0.7214266412620303 val acc per epoch => 0.7511867088607594 \n",
      "\n",
      "train loss per epoch =>  13 0.6773728566706333 train acc per epoch=>  0.7647858056265985\n",
      "val loss per epoch =>  0.6949130375928516 val acc per epoch => 0.7641416139240507 \n",
      "\n",
      "train loss per epoch =>  14 0.6570558029672374 train acc per epoch=>  0.7688818734015346\n",
      "val loss per epoch =>  0.6263426515874984 val acc per epoch => 0.7822389240506329 \n",
      "\n",
      "train loss per epoch =>  15 0.6446820967032781 train acc per epoch=>  0.7732296994580027\n",
      "val loss per epoch =>  0.7313945074624653 val acc per epoch => 0.752373417721519 \n",
      "\n",
      "train loss per epoch =>  16 0.6266427747428874 train acc per epoch=>  0.7810222186395884\n",
      "val loss per epoch =>  0.661902352601667 val acc per epoch => 0.772745253164557 \n",
      "\n",
      "train loss per epoch =>  17 0.6108976283951488 train acc per epoch=>  0.7862412085008743\n",
      "val loss per epoch =>  0.638459863919246 val acc per epoch => 0.7818433544303798 \n",
      "\n",
      "train loss per epoch =>  18 0.5997938816352268 train acc per epoch=>  0.7914482097491584\n",
      "val loss per epoch =>  0.6300100080574615 val acc per epoch => 0.7896558544303798 \n",
      "\n",
      "train loss per epoch =>  19 0.5895310979517524 train acc per epoch=>  0.7929987212276215\n",
      "val loss per epoch =>  0.6133486164521568 val acc per epoch => 0.7920292721518988 \n",
      "\n",
      "train loss per epoch =>  20 0.5760102345205634 train acc per epoch=>  0.7965992647973473\n",
      "val loss per epoch =>  0.5983116419254979 val acc per epoch => 0.7965783227848101 \n",
      "\n",
      "train loss per epoch =>  21 0.5676949682747922 train acc per epoch=>  0.79887707809658\n",
      "val loss per epoch =>  0.5690020752858512 val acc per epoch => 0.8091376582278481 \n",
      "\n",
      "train loss per epoch =>  22 0.5563458989343375 train acc per epoch=>  0.8028053069663474\n",
      "val loss per epoch =>  0.6437104050117203 val acc per epoch => 0.7852056962025317 \n",
      "\n",
      "train loss per epoch =>  23 0.5450060289839039 train acc per epoch=>  0.8088075448484982\n",
      "val loss per epoch =>  0.5673658361163321 val acc per epoch => 0.8072587025316456 \n",
      "\n",
      "train loss per epoch =>  24 0.5319067715378978 train acc per epoch=>  0.8130274936366264\n",
      "val loss per epoch =>  0.5903235851209375 val acc per epoch => 0.803995253164557 \n",
      "\n",
      "train loss per epoch =>  25 0.5246568937283342 train acc per epoch=>  0.8150775255754475\n",
      "val loss per epoch =>  0.6018402229381513 val acc per epoch => 0.796875 \n",
      "\n",
      "train loss per epoch =>  26 0.5162145259130336 train acc per epoch=>  0.8177869245219413\n",
      "val loss per epoch =>  0.6081091508835177 val acc per epoch => 0.7956882911392406 \n",
      "\n",
      "train loss per epoch =>  27 0.5079359874091185 train acc per epoch=>  0.821635230270493\n",
      "val loss per epoch =>  0.5770638769940485 val acc per epoch => 0.807060917721519 \n",
      "\n",
      "train loss per epoch =>  28 0.4976116802228991 train acc per epoch=>  0.8253276854219949\n",
      "val loss per epoch =>  0.6201476896110969 val acc per epoch => 0.7939082278481012 \n",
      "\n",
      "train loss per epoch =>  29 0.48911166960930885 train acc per epoch=>  0.8284886509866056\n",
      "val loss per epoch =>  0.57966964003406 val acc per epoch => 0.8073575949367089 \n",
      "\n",
      "train loss per epoch =>  30 0.4817287697054236 train acc per epoch=>  0.8277373720922738\n",
      "val loss per epoch =>  0.5485647626315491 val acc per epoch => 0.8199169303797469 \n",
      "\n",
      "train loss per epoch =>  31 0.47201893419560875 train acc per epoch=>  0.833647698240207\n",
      "val loss per epoch =>  0.6038676790798767 val acc per epoch => 0.7998417721518988 \n",
      "\n",
      "train loss per epoch =>  32 0.46921266851675175 train acc per epoch=>  0.8353140985264498\n",
      "val loss per epoch =>  0.5652946441233913 val acc per epoch => 0.8093354430379747 \n",
      "\n",
      "train loss per epoch =>  33 0.45534415226763164 train acc per epoch=>  0.8373841112836853\n",
      "val loss per epoch =>  0.5862107465538797 val acc per epoch => 0.8136867088607594 \n",
      "\n",
      "train loss per epoch =>  34 0.45085684623559724 train acc per epoch=>  0.8409367008587284\n",
      "val loss per epoch =>  0.5339652435689033 val acc per epoch => 0.8260482594936709 \n",
      "\n",
      "train loss per epoch =>  35 0.44507396937636157 train acc per epoch=>  0.8427789322555522\n",
      "val loss per epoch =>  0.5438216181495522 val acc per epoch => 0.821004746835443 \n",
      "\n",
      "train loss per epoch =>  36 0.4369668570320929 train acc per epoch=>  0.8461716752832807\n",
      "val loss per epoch =>  0.5144747439064558 val acc per epoch => 0.8297072784810127 \n",
      "\n",
      "train loss per epoch =>  37 0.4265041951175846 train acc per epoch=>  0.8484694694009278\n",
      "val loss per epoch =>  0.5213949510568305 val acc per epoch => 0.8300039556962026 \n",
      "\n",
      "train loss per epoch =>  38 0.42881551605966084 train acc per epoch=>  0.8486333120509487\n",
      "val loss per epoch =>  0.5951025244555895 val acc per epoch => 0.8080498417721519 \n",
      "\n",
      "train loss per epoch =>  39 0.41647718560970043 train acc per epoch=>  0.8516703964499257\n",
      "val loss per epoch =>  0.5399132725558703 val acc per epoch => 0.8224881329113924 \n",
      "\n",
      "train loss per epoch =>  40 0.4161515635678835 train acc per epoch=>  0.8522778133602094\n",
      "val loss per epoch =>  0.5240511117102225 val acc per epoch => 0.8313884493670886 \n",
      "\n",
      "train loss per epoch =>  41 0.4076303294705003 train acc per epoch=>  0.8542399296675192\n",
      "val loss per epoch =>  0.5628480654728564 val acc per epoch => 0.8198180379746836 \n",
      "\n",
      "train loss per epoch =>  42 0.39337135512200766 train acc per epoch=>  0.8586357097186701\n",
      "val loss per epoch =>  0.5432551640875732 val acc per epoch => 0.8215981012658228 \n",
      "\n",
      "train loss per epoch =>  43 0.39350751587344557 train acc per epoch=>  0.8606497762758104\n",
      "val loss per epoch =>  0.6084882337835771 val acc per epoch => 0.8117088607594937 \n",
      "\n",
      "train loss per epoch =>  44 0.3822457750739954 train acc per epoch=>  0.8647058824139178\n",
      "val loss per epoch =>  0.5387919982777366 val acc per epoch => 0.8240704113924051 \n",
      "\n",
      "train loss per epoch =>  45 0.3823733827875703 train acc per epoch=>  0.8656170077031226\n",
      "val loss per epoch =>  0.5630321095261392 val acc per epoch => 0.8230814873417721 \n",
      "\n",
      "train loss per epoch =>  46 0.3742017083994263 train acc per epoch=>  0.8661005434477725\n",
      "val loss per epoch =>  0.528804826962797 val acc per epoch => 0.8367286392405063 \n",
      "\n",
      "train loss per epoch =>  47 0.3682963585914553 train acc per epoch=>  0.8684382992022482\n",
      "val loss per epoch =>  0.5393163625952564 val acc per epoch => 0.8316851265822784 \n",
      "\n",
      "train loss per epoch =>  48 0.3606544537160098 train acc per epoch=>  0.8711437020460358\n",
      "val loss per epoch =>  0.5534670054912567 val acc per epoch => 0.8262460443037974 \n",
      "\n",
      "train loss per epoch =>  49 0.3583581964759266 train acc per epoch=>  0.8716032608695652\n",
      "val loss per epoch =>  0.5166937022269527 val acc per epoch => 0.8344541139240507 \n",
      "\n",
      "train loss per epoch =>  50 0.3576744498346773 train acc per epoch=>  0.8737452046950455\n",
      "val loss per epoch =>  0.513349014181125 val acc per epoch => 0.8377175632911392 \n",
      "\n",
      "train loss per epoch =>  51 0.35049434608358254 train acc per epoch=>  0.8746843031605186\n",
      "val loss per epoch =>  0.5215617742719529 val acc per epoch => 0.8397943037974683 \n",
      "\n",
      "train loss per epoch =>  52 0.34208169480418915 train acc per epoch=>  0.8773417520096235\n",
      "val loss per epoch =>  0.5249062836924686 val acc per epoch => 0.837618670886076 \n",
      "\n",
      "train loss per epoch =>  53 0.33642214239405854 train acc per epoch=>  0.8802709399586748\n",
      "val loss per epoch =>  0.5124237337444402 val acc per epoch => 0.839003164556962 \n",
      "\n",
      "train loss per epoch =>  54 0.33313674805566784 train acc per epoch=>  0.8796195653088562\n",
      "val loss per epoch =>  0.5454629237138773 val acc per epoch => 0.8329707278481012 \n",
      "\n",
      "train loss per epoch =>  55 0.32759027152567566 train acc per epoch=>  0.8831242007367751\n",
      "val loss per epoch =>  0.5227369183226477 val acc per epoch => 0.8394976265822784 \n",
      "\n",
      "train loss per epoch =>  56 0.32733488814605166 train acc per epoch=>  0.8833359975339202\n",
      "val loss per epoch =>  0.5153731967829451 val acc per epoch => 0.8385087025316456 \n",
      "\n",
      "train loss per epoch =>  57 0.3189169227543389 train acc per epoch=>  0.8868246483985726\n",
      "val loss per epoch =>  0.5194328163243547 val acc per epoch => 0.8391020569620253 \n",
      "\n",
      "train loss per epoch =>  58 0.316628768963887 train acc per epoch=>  0.8853700447570333\n",
      "val loss per epoch =>  0.5593427585650094 val acc per epoch => 0.831190664556962 \n",
      "\n",
      "train loss per epoch =>  59 0.30768292193370095 train acc per epoch=>  0.890888746894534\n",
      "val loss per epoch =>  0.5280347715450239 val acc per epoch => 0.8418710443037974 \n",
      "\n",
      "train loss per epoch =>  60 0.3070889786076363 train acc per epoch=>  0.8902653452685422\n",
      "val loss per epoch =>  0.5402536343170118 val acc per epoch => 0.8414754746835443 \n",
      "\n",
      "train loss per epoch =>  61 0.3032170434665802 train acc per epoch=>  0.8922554347521204\n",
      "val loss per epoch =>  0.5303465373153928 val acc per epoch => 0.8441455696202531 \n",
      "\n",
      "train loss per epoch =>  62 0.2944893255029493 train acc per epoch=>  0.8941416240409207\n",
      "val loss per epoch =>  0.5595672206033634 val acc per epoch => 0.8374208860759493 \n",
      "\n",
      "train loss per epoch =>  63 0.2924139625428583 train acc per epoch=>  0.894221547314578\n",
      "val loss per epoch =>  0.5487888376169567 val acc per epoch => 0.8368275316455697 \n",
      "\n",
      "train loss per epoch =>  64 0.2910955785333043 train acc per epoch=>  0.8958639706797002\n",
      "val loss per epoch =>  0.5239699554594257 val acc per epoch => 0.8438488924050633 \n",
      "\n",
      "train loss per epoch =>  65 0.28323074155832495 train acc per epoch=>  0.8982936381683935\n",
      "val loss per epoch =>  0.5538368077972268 val acc per epoch => 0.8398931962025317 \n",
      "\n",
      "train loss per epoch =>  66 0.27891720433140654 train acc per epoch=>  0.9002317775545827\n",
      "val loss per epoch =>  0.5572053786320023 val acc per epoch => 0.8399920886075949 \n",
      "\n",
      "train loss per epoch =>  67 0.27519994474890286 train acc per epoch=>  0.9017703005724855\n",
      "val loss per epoch =>  0.5698618296580978 val acc per epoch => 0.8346518987341772 \n",
      "\n",
      "train loss per epoch =>  68 0.2692265518943367 train acc per epoch=>  0.9036445012482841\n",
      "val loss per epoch =>  0.5892874685269368 val acc per epoch => 0.833564082278481 \n",
      "\n",
      "train loss per epoch =>  69 0.26341860865235633 train acc per epoch=>  0.9056945333395467\n",
      "val loss per epoch =>  0.5756538242478914 val acc per epoch => 0.8381131329113924 \n",
      "\n",
      "train loss per epoch =>  70 0.2628754750465798 train acc per epoch=>  0.9053109015345269\n",
      "val loss per epoch =>  0.5764516727833808 val acc per epoch => 0.8367286392405063 \n",
      "\n",
      "train loss per epoch =>  71 0.25889323884263976 train acc per epoch=>  0.9066336318050199\n",
      "val loss per epoch =>  0.5495770637747608 val acc per epoch => 0.8475079113924051 \n",
      "\n",
      "train loss per epoch =>  72 0.2569902780491983 train acc per epoch=>  0.9079763427414858\n",
      "val loss per epoch =>  0.5690956775900684 val acc per epoch => 0.8412776898734177 \n",
      "\n",
      "train loss per epoch =>  73 0.25605832213712165 train acc per epoch=>  0.9078764386494141\n",
      "val loss per epoch =>  0.566878393858294 val acc per epoch => 0.8434533227848101 \n",
      "\n",
      "train loss per epoch =>  74 0.2483465201066583 train acc per epoch=>  0.9104020141274728\n",
      "val loss per epoch =>  0.5590216283556781 val acc per epoch => 0.8432555379746836 \n",
      "\n",
      "train loss per epoch =>  75 0.2448039267907667 train acc per epoch=>  0.9119844948849105\n",
      "val loss per epoch =>  0.5803085369399831 val acc per epoch => 0.8393987341772152 \n",
      "\n",
      "train loss per epoch =>  76 0.24293615415578 train acc per epoch=>  0.9126518542504372\n",
      "val loss per epoch =>  0.5468432420416723 val acc per epoch => 0.8452333860759493 \n",
      "\n",
      "train loss per epoch =>  77 0.23222105340350924 train acc per epoch=>  0.9153212915601023\n",
      "val loss per epoch =>  0.5986669074885452 val acc per epoch => 0.8398931962025317 \n",
      "\n",
      "train loss per epoch =>  78 0.23348573911601625 train acc per epoch=>  0.9164402173913043\n",
      "val loss per epoch =>  0.5469645771044719 val acc per epoch => 0.8460245253164557 \n",
      "\n",
      "train loss per epoch =>  79 0.22532241696210772 train acc per epoch=>  0.9192095587930411\n",
      "val loss per epoch =>  0.5557690815457815 val acc per epoch => 0.8469145569620253 \n",
      "\n",
      "train loss per epoch =>  80 0.22767131933775706 train acc per epoch=>  0.9171635231093678\n",
      "val loss per epoch =>  0.624725371976442 val acc per epoch => 0.8349485759493671 \n",
      "\n",
      "train loss per epoch =>  81 0.2229228805169425 train acc per epoch=>  0.9215433184448105\n",
      "val loss per epoch =>  0.5768079795414889 val acc per epoch => 0.8471123417721519 \n",
      "\n",
      "train loss per epoch =>  82 0.2185937146777692 train acc per epoch=>  0.9208759590792839\n",
      "val loss per epoch =>  0.5781828406490858 val acc per epoch => 0.8479034810126582 \n",
      "\n",
      "train loss per epoch =>  83 0.22050897721820475 train acc per epoch=>  0.9213035486238387\n",
      "val loss per epoch =>  0.5828092283085932 val acc per epoch => 0.8463212025316456 \n",
      "\n",
      "train loss per epoch =>  84 0.21136815682091675 train acc per epoch=>  0.9233016304652709\n",
      "val loss per epoch =>  0.5989117358304277 val acc per epoch => 0.8395965189873418 \n",
      "\n",
      "train loss per epoch =>  85 0.20754123959318757 train acc per epoch=>  0.9256713554987213\n",
      "val loss per epoch =>  0.6091781213313718 val acc per epoch => 0.8424643987341772 \n",
      "\n",
      "train loss per epoch =>  86 0.2077373983838674 train acc per epoch=>  0.9249160806541248\n",
      "val loss per epoch =>  0.5967349493050877 val acc per epoch => 0.8400909810126582 \n",
      "\n",
      "train loss per epoch =>  87 0.20174992334126207 train acc per epoch=>  0.9274416559797418\n",
      "val loss per epoch =>  0.6155958462365066 val acc per epoch => 0.8381131329113924 \n",
      "\n",
      "train loss per epoch =>  88 0.19672531482127623 train acc per epoch=>  0.9281289961636828\n",
      "val loss per epoch =>  0.5804801783229732 val acc per epoch => 0.8438488924050633 \n",
      "\n",
      "train loss per epoch =>  89 0.18951867705644548 train acc per epoch=>  0.9322290601937667\n",
      "val loss per epoch =>  0.5861962033977991 val acc per epoch => 0.8458267405063291 \n",
      "\n",
      "train loss per epoch =>  90 0.19227264402315136 train acc per epoch=>  0.9317695013702373\n",
      "val loss per epoch =>  0.605424804966661 val acc per epoch => 0.8460245253164557 \n",
      "\n",
      "train loss per epoch =>  91 0.19240212672964083 train acc per epoch=>  0.9310222187310534\n",
      "val loss per epoch =>  0.5934646376703359 val acc per epoch => 0.8509691455696202 \n",
      "\n",
      "train loss per epoch =>  92 0.18735998167711146 train acc per epoch=>  0.9330962275909951\n",
      "val loss per epoch =>  0.6069826789294617 val acc per epoch => 0.8440466772151899 \n",
      "\n",
      "train loss per epoch =>  93 0.1786101277908096 train acc per epoch=>  0.9368486253501814\n",
      "val loss per epoch =>  0.6028998094268992 val acc per epoch => 0.8483979430379747 \n",
      "\n",
      "train loss per epoch =>  94 0.17923288405551324 train acc per epoch=>  0.9362452046950455\n",
      "val loss per epoch =>  0.604932234634327 val acc per epoch => 0.8482001582278481 \n",
      "\n",
      "train loss per epoch =>  95 0.17786772179481625 train acc per epoch=>  0.9366128516319158\n",
      "val loss per epoch =>  0.609207157470003 val acc per epoch => 0.8504746835443038 \n",
      "\n",
      "train loss per epoch =>  96 0.17337572376441468 train acc per epoch=>  0.9377717390999465\n",
      "val loss per epoch =>  0.5898554491091378 val acc per epoch => 0.8504746835443038 \n",
      "\n",
      "train loss per epoch =>  97 0.16900733404356957 train acc per epoch=>  0.938822730270493\n",
      "val loss per epoch =>  0.622247306229193 val acc per epoch => 0.8511669303797469 \n",
      "\n",
      "train loss per epoch =>  98 0.16623834656823017 train acc per epoch=>  0.9394301470283353\n",
      "val loss per epoch =>  0.6141545738600478 val acc per epoch => 0.8500791139240507 \n",
      "\n",
      "train loss per epoch =>  99 0.16213719542031094 train acc per epoch=>  0.9414522059433296\n",
      "val loss per epoch =>  0.6051913443245466 val acc per epoch => 0.8533425632911392 \n",
      "\n",
      "train loss per epoch =>  100 0.16183988517507567 train acc per epoch=>  0.9421235614115625\n",
      "val loss per epoch =>  0.6116649334943747 val acc per epoch => 0.8496835443037974 \n",
      "\n",
      "train loss per epoch =>  101 0.1596343756827247 train acc per epoch=>  0.9420636189563195\n",
      "val loss per epoch =>  0.6493773622603356 val acc per epoch => 0.8466178797468354 \n",
      "\n",
      "train loss per epoch =>  102 0.15582106477769134 train acc per epoch=>  0.9433903453295188\n",
      "val loss per epoch =>  0.637096946752524 val acc per epoch => 0.8465189873417721 \n",
      "\n",
      "train loss per epoch =>  103 0.15029142653126545 train acc per epoch=>  0.9454763428024624\n",
      "val loss per epoch =>  0.638425861544247 val acc per epoch => 0.853935917721519 \n",
      "\n",
      "train loss per epoch =>  104 0.15134006926356375 train acc per epoch=>  0.9457440856472611\n",
      "val loss per epoch =>  0.6229781233057191 val acc per epoch => 0.8494857594936709 \n",
      "\n",
      "train loss per epoch =>  105 0.1481743112606618 train acc per epoch=>  0.9486932545671682\n",
      "val loss per epoch =>  0.6591022523898112 val acc per epoch => 0.8487935126582279 \n",
      "\n",
      "train loss per epoch =>  106 0.14115758537483947 train acc per epoch=>  0.9497122763062987\n",
      "val loss per epoch =>  0.6235389650999745 val acc per epoch => 0.8490901898734177 \n",
      "\n",
      "train loss per epoch =>  107 0.1463887850894495 train acc per epoch=>  0.9462116368286445\n",
      "val loss per epoch =>  0.6417488685891598 val acc per epoch => 0.8499802215189873 \n",
      "\n",
      "train loss per epoch =>  108 0.14285923969334044 train acc per epoch=>  0.9485214194068519\n",
      "val loss per epoch =>  0.620913465566273 val acc per epoch => 0.8547270569620253 \n",
      "\n",
      "train loss per epoch =>  109 0.13525539821447313 train acc per epoch=>  0.953244884910486\n",
      "val loss per epoch =>  0.672871282206306 val acc per epoch => 0.8480023734177216 \n",
      "\n",
      "train loss per epoch =>  110 0.13485229266878893 train acc per epoch=>  0.9505714514981145\n",
      "val loss per epoch =>  0.662624935183344 val acc per epoch => 0.8492879746835443 \n",
      "\n",
      "train loss per epoch =>  111 0.13150925993862206 train acc per epoch=>  0.9528053069053708\n",
      "val loss per epoch =>  0.6382291300010078 val acc per epoch => 0.853935917721519 \n",
      "\n",
      "train loss per epoch =>  112 0.12684297429211913 train acc per epoch=>  0.9538922634575983\n",
      "val loss per epoch =>  0.6765007527568673 val acc per epoch => 0.8497824367088608 \n",
      "\n",
      "train loss per epoch =>  113 0.12611975749511548 train acc per epoch=>  0.954303868286445\n",
      "val loss per epoch =>  0.67811029998562 val acc per epoch => 0.8492879746835443 \n",
      "\n",
      "train loss per epoch =>  114 0.1268883824653333 train acc per epoch=>  0.9550791241018973\n",
      "val loss per epoch =>  0.6603437266017818 val acc per epoch => 0.8507713607594937 \n",
      "\n",
      "train loss per epoch =>  115 0.12008144760318577 train acc per epoch=>  0.9563578964804139\n",
      "val loss per epoch =>  0.6926352306257321 val acc per epoch => 0.8463212025316456 \n",
      "\n",
      "train loss per epoch =>  116 0.12128325128722983 train acc per epoch=>  0.9565736892278237\n",
      "val loss per epoch =>  0.6586280257641515 val acc per epoch => 0.8559137658227848 \n",
      "\n",
      "train loss per epoch =>  117 0.11706224190133155 train acc per epoch=>  0.9580242967666568\n",
      "val loss per epoch =>  0.6683930034124399 val acc per epoch => 0.8504746835443038 \n",
      "\n",
      "train loss per epoch =>  118 0.11398006872752743 train acc per epoch=>  0.9587875639691072\n",
      "val loss per epoch =>  0.6682498149479492 val acc per epoch => 0.8533425632911392 \n",
      "\n",
      "train loss per epoch =>  119 0.11676763828910525 train acc per epoch=>  0.9587236254111581\n",
      "val loss per epoch =>  0.6670589556422415 val acc per epoch => 0.8515625 \n",
      "\n",
      "train loss per epoch =>  120 0.11008743385372259 train acc per epoch=>  0.9609614770735622\n",
      "val loss per epoch =>  0.6802021619639819 val acc per epoch => 0.8531447784810127 \n",
      "\n",
      "train loss per epoch =>  121 0.11070441996292843 train acc per epoch=>  0.9604619566132041\n",
      "val loss per epoch =>  0.685685516912726 val acc per epoch => 0.8509691455696202 \n",
      "\n",
      "train loss per epoch =>  122 0.1082129303432639 train acc per epoch=>  0.9608455882657825\n",
      "val loss per epoch =>  0.6728216258785392 val acc per epoch => 0.854628164556962 \n",
      "\n",
      "train loss per epoch =>  123 0.10367942610017174 train acc per epoch=>  0.9628916241018973\n",
      "val loss per epoch =>  0.6854118636891812 val acc per epoch => 0.8512658227848101 \n",
      "\n",
      "train loss per epoch =>  124 0.10601789904448687 train acc per epoch=>  0.9623441496468566\n",
      "val loss per epoch =>  0.68100656399244 val acc per epoch => 0.8549248417721519 \n",
      "\n",
      "train loss per epoch =>  125 0.1041711212595558 train acc per epoch=>  0.9632752557544757\n",
      "val loss per epoch =>  0.6798191538339928 val acc per epoch => 0.8524525316455697 \n",
      "\n",
      "train loss per epoch =>  126 0.10266373278882802 train acc per epoch=>  0.9636588875594956\n",
      "val loss per epoch =>  0.687075404049475 val acc per epoch => 0.8506724683544303 \n",
      "\n",
      "train loss per epoch =>  127 0.09740918147308594 train acc per epoch=>  0.9657968351298281\n",
      "val loss per epoch =>  0.7172946628135971 val acc per epoch => 0.8474090189873418 \n",
      "\n",
      "train loss per epoch =>  128 0.09488571244184776 train acc per epoch=>  0.9651814258616903\n",
      "val loss per epoch =>  0.7010363747801962 val acc per epoch => 0.8523536392405063 \n",
      "\n",
      "train loss per epoch =>  129 0.0938189200142308 train acc per epoch=>  0.9660406010535062\n",
      "val loss per epoch =>  0.7088699023934859 val acc per epoch => 0.8534414556962026 \n",
      "\n",
      "train loss per epoch =>  130 0.09391230387170144 train acc per epoch=>  0.9670556266899304\n",
      "val loss per epoch =>  0.7208434152829496 val acc per epoch => 0.8526503164556962 \n",
      "\n",
      "train loss per epoch =>  131 0.0913248560427095 train acc per epoch=>  0.9679867327975495\n",
      "val loss per epoch =>  0.6843120063407512 val acc per epoch => 0.8557159810126582 \n",
      "\n",
      "train loss per epoch =>  132 0.08963003624564089 train acc per epoch=>  0.9679108056265985\n",
      "val loss per epoch =>  0.6866126984735078 val acc per epoch => 0.8551226265822784 \n",
      "\n",
      "train loss per epoch =>  133 0.0840611864367257 train acc per epoch=>  0.9698809142917624\n",
      "val loss per epoch =>  0.7114965506369555 val acc per epoch => 0.8516613924050633 \n",
      "\n",
      "train loss per epoch =>  134 0.0874066954654882 train acc per epoch=>  0.96875\n",
      "val loss per epoch =>  0.7074345970832849 val acc per epoch => 0.8567049050632911 \n",
      "\n",
      "train loss per epoch =>  135 0.08192668598897927 train acc per epoch=>  0.9702845269151966\n",
      "val loss per epoch =>  0.7090346303921712 val acc per epoch => 0.850870253164557 \n",
      "\n",
      "train loss per epoch =>  136 0.08130041456988553 train acc per epoch=>  0.9705362851967287\n",
      "val loss per epoch =>  0.7015452373631393 val acc per epoch => 0.8535403481012658 \n",
      "\n",
      "train loss per epoch =>  137 0.08226377325480247 train acc per epoch=>  0.9704763427414858\n",
      "val loss per epoch =>  0.7090347277212746 val acc per epoch => 0.8572982594936709 \n",
      "\n",
      "train loss per epoch =>  138 0.07788552826894518 train acc per epoch=>  0.9724704284802117\n",
      "val loss per epoch =>  0.7211087942123413 val acc per epoch => 0.8535403481012658 \n",
      "\n",
      "train loss per epoch =>  139 0.0780088942726631 train acc per epoch=>  0.9727022059433296\n",
      "val loss per epoch =>  0.7079927523302126 val acc per epoch => 0.8540348101265823 \n",
      "\n",
      "train loss per epoch =>  140 0.07305628833982646 train acc per epoch=>  0.9736413044088027\n",
      "val loss per epoch =>  0.7165523759926422 val acc per epoch => 0.8568037974683544 \n",
      "\n",
      "train loss per epoch =>  141 0.07684321089140365 train acc per epoch=>  0.9731497763062987\n",
      "val loss per epoch =>  0.711031001957157 val acc per epoch => 0.8554193037974683 \n",
      "\n",
      "train loss per epoch =>  142 0.07351401257697883 train acc per epoch=>  0.9743486254111581\n",
      "val loss per epoch =>  0.7141061100778701 val acc per epoch => 0.8569026898734177 \n",
      "\n",
      "train loss per epoch =>  143 0.07293422221708709 train acc per epoch=>  0.9753556585372867\n",
      "val loss per epoch =>  0.7287489387053477 val acc per epoch => 0.8555181962025317 \n",
      "\n",
      "train loss per epoch =>  144 0.07689033899827839 train acc per epoch=>  0.9734015345878309\n",
      "val loss per epoch =>  0.7289905382108085 val acc per epoch => 0.8552215189873418 \n",
      "\n",
      "train loss per epoch =>  145 0.068281890071757 train acc per epoch=>  0.9752557544452151\n",
      "val loss per epoch =>  0.7257502697691133 val acc per epoch => 0.8565071202531646 \n",
      "\n",
      "train loss per epoch =>  146 0.06885713474620181 train acc per epoch=>  0.9765385230788795\n",
      "val loss per epoch =>  0.7181804972358897 val acc per epoch => 0.8569026898734177 \n",
      "\n",
      "train loss per epoch =>  147 0.06770712263701135 train acc per epoch=>  0.9756393862502349\n",
      "val loss per epoch =>  0.7230342626571655 val acc per epoch => 0.8559137658227848 \n",
      "\n",
      "train loss per epoch =>  148 0.06443109887811686 train acc per epoch=>  0.9773577366338666\n",
      "val loss per epoch =>  0.7260432139604907 val acc per epoch => 0.8560126582278481 \n",
      "\n",
      "train loss per epoch =>  149 0.06348676376444909 train acc per epoch=>  0.9775215792838875\n",
      "val loss per epoch =>  0.7323003126473366 val acc per epoch => 0.8560126582278481 \n",
      "\n",
      "train loss per epoch =>  150 0.0654212928560498 train acc per epoch=>  0.9774096867312556\n",
      "val loss per epoch =>  0.7255015393978432 val acc per epoch => 0.8578916139240507 \n",
      "\n",
      "train loss per epoch =>  151 0.06169237098073029 train acc per epoch=>  0.9786684782913578\n",
      "val loss per epoch =>  0.735283349133745 val acc per epoch => 0.8540348101265823 \n",
      "\n",
      "train loss per epoch =>  152 0.05987580481659421 train acc per epoch=>  0.9789562021070124\n",
      "val loss per epoch =>  0.7302788801585571 val acc per epoch => 0.8544303797468354 \n",
      "\n",
      "train loss per epoch =>  153 0.05789512000701693 train acc per epoch=>  0.980346867038161\n",
      "val loss per epoch =>  0.7287718042542662 val acc per epoch => 0.857001582278481 \n",
      "\n",
      "train loss per epoch =>  154 0.05891724411741166 train acc per epoch=>  0.9792159527463986\n",
      "val loss per epoch =>  0.7404546300067177 val acc per epoch => 0.8584849683544303 \n",
      "\n",
      "train loss per epoch =>  155 0.06060642802782947 train acc per epoch=>  0.9781849425467078\n",
      "val loss per epoch =>  0.7533383403397813 val acc per epoch => 0.8555181962025317 \n",
      "\n",
      "train loss per epoch =>  156 0.05830681667713177 train acc per epoch=>  0.9796035806541248\n",
      "val loss per epoch =>  0.7338909329492834 val acc per epoch => 0.8571004746835443 \n",
      "\n",
      "train loss per epoch =>  157 0.05530571515726693 train acc per epoch=>  0.9805346867617439\n",
      "val loss per epoch =>  0.7435035430177858 val acc per epoch => 0.859375 \n",
      "\n",
      "train loss per epoch =>  158 0.05572411412244563 train acc per epoch=>  0.9803268862197466\n",
      "val loss per epoch =>  0.7465215061284318 val acc per epoch => 0.857001582278481 \n",
      "\n",
      "train loss per epoch =>  159 0.055651604252703046 train acc per epoch=>  0.9813459079588771\n",
      "val loss per epoch =>  0.7418994247158871 val acc per epoch => 0.857693829113924 \n",
      "\n",
      "train loss per epoch =>  160 0.05324382131057017 train acc per epoch=>  0.981465792869363\n",
      "val loss per epoch =>  0.7381107139436505 val acc per epoch => 0.858682753164557 \n",
      "\n",
      "train loss per epoch =>  161 0.05409297964337956 train acc per epoch=>  0.9808024297589841\n",
      "val loss per epoch =>  0.749841354315794 val acc per epoch => 0.8574960443037974 \n",
      "\n",
      "train loss per epoch =>  162 0.05333692112894695 train acc per epoch=>  0.9813139386799025\n",
      "val loss per epoch =>  0.7456317902365818 val acc per epoch => 0.8571004746835443 \n",
      "\n",
      "train loss per epoch =>  163 0.054063718832667224 train acc per epoch=>  0.9815537085008743\n",
      "val loss per epoch =>  0.7502452055864697 val acc per epoch => 0.8554193037974683 \n",
      "\n",
      "train loss per epoch =>  164 0.05207221047080996 train acc per epoch=>  0.9823049872427645\n",
      "val loss per epoch =>  0.7414463732061507 val acc per epoch => 0.8569026898734177 \n",
      "\n",
      "train loss per epoch =>  165 0.048944428031954465 train acc per epoch=>  0.9828045077031226\n",
      "val loss per epoch =>  0.7506085302256331 val acc per epoch => 0.8565071202531646 \n",
      "\n",
      "train loss per epoch =>  166 0.051177599888933285 train acc per epoch=>  0.9827525576057337\n",
      "val loss per epoch =>  0.7488226056853428 val acc per epoch => 0.8562104430379747 \n",
      "\n",
      "train loss per epoch =>  167 0.05186636749026187 train acc per epoch=>  0.9820532289612324\n",
      "val loss per epoch =>  0.748136926300918 val acc per epoch => 0.8587816455696202 \n",
      "\n",
      "train loss per epoch =>  168 0.04917491244538056 train acc per epoch=>  0.9832201087871171\n",
      "val loss per epoch =>  0.7585534581655189 val acc per epoch => 0.8574960443037974 \n",
      "\n",
      "train loss per epoch =>  169 0.050103473088816 train acc per epoch=>  0.9826766304347826\n",
      "val loss per epoch =>  0.7534602073174489 val acc per epoch => 0.8604628164556962 \n",
      "\n",
      "train loss per epoch =>  170 0.049877953715622425 train acc per epoch=>  0.9827445652478796\n",
      "val loss per epoch =>  0.7415205142166041 val acc per epoch => 0.8584849683544303 \n",
      "\n",
      "train loss per epoch =>  171 0.04964423273711482 train acc per epoch=>  0.9830522698819485\n",
      "val loss per epoch =>  0.7513982027391845 val acc per epoch => 0.8573971518987342 \n",
      "\n",
      "train loss per epoch =>  172 0.046778755362533855 train acc per epoch=>  0.9839394182500327\n",
      "val loss per epoch =>  0.746878023011775 val acc per epoch => 0.8568037974683544 \n",
      "\n",
      "train loss per epoch =>  173 0.04804375890137442 train acc per epoch=>  0.9839793798868613\n",
      "val loss per epoch =>  0.755671799937381 val acc per epoch => 0.8575949367088608 \n",
      "\n",
      "train loss per epoch =>  174 0.04710663752892362 train acc per epoch=>  0.9835717711607208\n",
      "val loss per epoch =>  0.754124624065206 val acc per epoch => 0.8568037974683544 \n",
      "\n",
      "train loss per epoch =>  175 0.046507499916741 train acc per epoch=>  0.9840033568079819\n",
      "val loss per epoch =>  0.7507778926740719 val acc per epoch => 0.8584849683544303 \n",
      "\n",
      "train loss per epoch =>  176 0.04612259529626278 train acc per epoch=>  0.9843789962551478\n",
      "val loss per epoch =>  0.7560588566562797 val acc per epoch => 0.8566060126582279 \n",
      "\n",
      "train loss per epoch =>  177 0.04407028772432328 train acc per epoch=>  0.9851502558154523\n",
      "val loss per epoch =>  0.7550293739083447 val acc per epoch => 0.8581882911392406 \n",
      "\n",
      "train loss per epoch =>  178 0.04738446072106014 train acc per epoch=>  0.9835637788028668\n",
      "val loss per epoch =>  0.75476474475257 val acc per epoch => 0.8578916139240507 \n",
      "\n",
      "train loss per epoch =>  179 0.04535132138025197 train acc per epoch=>  0.9839314258921786\n",
      "val loss per epoch =>  0.7614426103573811 val acc per epoch => 0.8594738924050633 \n",
      "\n",
      "train loss per epoch =>  180 0.04518489642283115 train acc per epoch=>  0.9847026854524832\n",
      "val loss per epoch =>  0.7632173944877673 val acc per epoch => 0.8592761075949367 \n",
      "\n",
      "train loss per epoch =>  181 0.04255727750351629 train acc per epoch=>  0.9853220908233272\n",
      "val loss per epoch =>  0.7595786425886275 val acc per epoch => 0.859375 \n",
      "\n",
      "train loss per epoch =>  182 0.04493946402721927 train acc per epoch=>  0.985569853002153\n",
      "val loss per epoch =>  0.7598858336104622 val acc per epoch => 0.8594738924050633 \n",
      "\n",
      "train loss per epoch =>  183 0.04489938204374422 train acc per epoch=>  0.9848145780051151\n",
      "val loss per epoch =>  0.7567510978330539 val acc per epoch => 0.858682753164557 \n",
      "\n",
      "train loss per epoch =>  184 0.04283532731073058 train acc per epoch=>  0.9857416880100279\n",
      "val loss per epoch =>  0.7585115983516355 val acc per epoch => 0.8583860759493671 \n",
      "\n",
      "train loss per epoch =>  185 0.0410583216001463 train acc per epoch=>  0.9863331202046036\n",
      "val loss per epoch =>  0.7557449963273881 val acc per epoch => 0.8596716772151899 \n",
      "\n",
      "train loss per epoch =>  186 0.0450909879211041 train acc per epoch=>  0.984638746894534\n",
      "val loss per epoch =>  0.7634032836443261 val acc per epoch => 0.859375 \n",
      "\n",
      "train loss per epoch =>  187 0.044927640590588076 train acc per epoch=>  0.9848705243576518\n",
      "val loss per epoch =>  0.7574358250521407 val acc per epoch => 0.8602650316455697 \n",
      "\n",
      "train loss per epoch =>  188 0.04367750033240794 train acc per epoch=>  0.985366048562862\n",
      "val loss per epoch =>  0.7543114733092392 val acc per epoch => 0.8589794303797469 \n",
      "\n",
      "train loss per epoch =>  189 0.04317166001590736 train acc per epoch=>  0.984934462915601\n",
      "val loss per epoch =>  0.7529620973369743 val acc per epoch => 0.8596716772151899 \n",
      "\n",
      "train loss per epoch =>  190 0.042648767822605495 train acc per epoch=>  0.9856537723785166\n",
      "val loss per epoch =>  0.7554556093638456 val acc per epoch => 0.8592761075949367 \n",
      "\n",
      "train loss per epoch =>  191 0.040931160074642016 train acc per epoch=>  0.9861213235599001\n",
      "val loss per epoch =>  0.7555110895935493 val acc per epoch => 0.8591772151898734 \n",
      "\n",
      "train loss per epoch =>  192 0.04161779742564082 train acc per epoch=>  0.9853540601023018\n",
      "val loss per epoch =>  0.7598772018770629 val acc per epoch => 0.8595727848101266 \n",
      "\n",
      "train loss per epoch =>  193 0.0416770413115411 train acc per epoch=>  0.9864530051150895\n",
      "val loss per epoch =>  0.7565446990200236 val acc per epoch => 0.8611550632911392 \n",
      "\n",
      "train loss per epoch =>  194 0.04230315962096538 train acc per epoch=>  0.9859295077336109\n",
      "val loss per epoch =>  0.7544022115725505 val acc per epoch => 0.8607594936708861 \n",
      "\n",
      "train loss per epoch =>  195 0.04281230316475949 train acc per epoch=>  0.9854739450127877\n",
      "val loss per epoch =>  0.7588561992102032 val acc per epoch => 0.8601661392405063 \n",
      "\n",
      "train loss per epoch =>  196 0.04287026922964036 train acc per epoch=>  0.9860493926440969\n",
      "val loss per epoch =>  0.7584995872612241 val acc per epoch => 0.8604628164556962 \n",
      "\n",
      "train loss per epoch =>  197 0.04357756733122613 train acc per epoch=>  0.9856697570942247\n",
      "val loss per epoch =>  0.756420060426374 val acc per epoch => 0.8602650316455697 \n",
      "\n",
      "train loss per epoch =>  198 0.0430450907365307 train acc per epoch=>  0.9848625319997978\n",
      "val loss per epoch =>  0.758995766881146 val acc per epoch => 0.8603639240506329 \n",
      "\n",
      "train loss per epoch =>  199 0.040439716187160454 train acc per epoch=>  0.9866328324808185\n",
      "val loss per epoch =>  0.7552422982982442 val acc per epoch => 0.8606606012658228 \n",
      "\n",
      "CPU times: user 25min 41s, sys: 5min 17s, total: 30min 59s\n",
      "Wall time: 32min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomCrop(size=32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(20),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "     ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True,transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "                            ]))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "model =ResNetF()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "  \n",
    "\n",
    "loss =10\n",
    "train_loss_history=[]\n",
    "train_acc_history=[]\n",
    "test_loss_history=[]\n",
    "test_acc_history=[]\n",
    "EPOCHS=200\n",
    "for i in range(EPOCHS):\n",
    "    # using train iterator\n",
    "    train_loss , epoch_acc = train(model,trainloader, optimizer, criterion, device=device)\n",
    "    print(\"train loss per epoch => \", i, train_loss, \"train acc per epoch=> \" , epoch_acc)\n",
    "    \n",
    "    epoch_loss , epoch_valid_acc = evaluate(model, testloader, criterion, device)\n",
    "    print(\"val loss per epoch => \", epoch_loss , \"val acc per epoch =>\",epoch_valid_acc,\"\\n\")\n",
    "        \n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "    test_loss_history.append(epoch_loss)\n",
    "    test_acc_history.append(epoch_valid_acc)\n",
    "    \n",
    "    if epoch_loss<loss:\n",
    "        torch.save(model,\"./res_512.pt\")\n",
    "        loss= epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611550632911392"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.savetxt(\"./train_acc_history.txt\",train_acc_history)\n",
    "np.savetxt(\"./train_loss_history.txt\",train_loss_history)\n",
    "np.savetxt(\"./test_acc_history.txt\",test_acc_history)\n",
    "np.savetxt(\"./test_loss_history.txt\",test_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
