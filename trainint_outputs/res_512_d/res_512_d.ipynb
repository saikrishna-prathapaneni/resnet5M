{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "           Dropout-7           [-1, 64, 56, 56]               0\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "           ResNet-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "          Dropout-14           [-1, 64, 56, 56]               0\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "           ResNet-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "          Dropout-21           [-1, 64, 56, 56]               0\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 56, 56]             128\n",
      "           ResNet-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "          Dropout-28          [-1, 128, 28, 28]               0\n",
      "             ReLU-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "           Conv2d-32          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "           ResNet-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "          Dropout-37          [-1, 128, 28, 28]               0\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 28, 28]             256\n",
      "           ResNet-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "          Dropout-44          [-1, 128, 28, 28]               0\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "           ResNet-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "          Dropout-51          [-1, 128, 28, 28]               0\n",
      "             ReLU-52          [-1, 128, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "           ResNet-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "          Dropout-58          [-1, 128, 28, 28]               0\n",
      "             ReLU-59          [-1, 128, 28, 28]               0\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "           ResNet-62          [-1, 128, 28, 28]               0\n",
      "           Conv2d-63          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-64          [-1, 128, 28, 28]             256\n",
      "          Dropout-65          [-1, 128, 28, 28]               0\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "           ResNet-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 14, 14]         589,824\n",
      "      BatchNorm2d-71          [-1, 512, 14, 14]           1,024\n",
      "          Dropout-72          [-1, 512, 14, 14]               0\n",
      "             ReLU-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-75          [-1, 512, 14, 14]           1,024\n",
      "           Conv2d-76          [-1, 512, 14, 14]          65,536\n",
      "      BatchNorm2d-77          [-1, 512, 14, 14]           1,024\n",
      "           ResNet-78          [-1, 512, 14, 14]               0\n",
      "AdaptiveAvgPool2d-79            [-1, 512, 1, 1]               0\n",
      "          Flatten-80                  [-1, 512]               0\n",
      "           Linear-81                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 4,961,610\n",
      "Trainable params: 4,961,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 92.65\n",
      "Params size (MB): 18.93\n",
      "Estimated Total Size (MB): 112.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, inchannels, outchannels, kernel_size=3, stride=1, skip=True):\n",
    "        super().__init__()\n",
    "        self.skip = skip\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(inchannels, outchannels, kernel_size=kernel_size, stride=stride, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannels, outchannels, kernel_size=kernel_size, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(outchannels),\n",
    "           \n",
    "        )\n",
    "        if stride == 2 or inchannels != outchannels:\n",
    "            self.skip = False\n",
    "            self.skip_conv = nn.Conv2d(inchannels, outchannels, kernel_size=1, stride=stride,bias=False)\n",
    "            self.skip_bn = nn.BatchNorm2d(outchannels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if not self.skip:\n",
    "            out += self.skip_bn(self.skip_conv(x))\n",
    "        else:\n",
    "            out += x\n",
    "        out = F.relu(out.clone())\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,stride=2, padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        #self.resblock1 = ResNet(32, 32,stride=1)\n",
    "        #self.resblock2 = ResNet(64, 64,stride=1)\n",
    "        self.resblock3 = ResNet(64, 64,stride=1)\n",
    "        #self.resblock4=ResNet(64,64,stride=1)\n",
    "        #self.resblock5=ResNet(64,64,stride=1)\n",
    "        self.resblock6=ResNet(64,64,stride=1)\n",
    "        self.resblock7=ResNet(64,64,stride=1)\n",
    "        self.resblock8=ResNet(64,128,stride=2)\n",
    "        self.resblock9=ResNet(128,128,stride=1)\n",
    "        self.resblock10=ResNet(128,128,stride=1)\n",
    "        self.resblock11=ResNet(128,128,stride=1)\n",
    "        self.resblock12=ResNet(128,128,stride=1)\n",
    "        self.resblock13=ResNet(128,128,stride=1)\n",
    "        self.resblock14 =ResNet(128,512,stride=2)\n",
    "       #self.resblock15 =ResNet(512,512,stride=1)\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.flat=nn.Flatten()\n",
    "        self.fc1= nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x.clone())\n",
    "        x = self.maxpool(x)\n",
    "        #x = self.resblock1(x)\n",
    "        #x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        #x = self.resblock4(x)\n",
    "        #x = self.resblock5(x)\n",
    "        x = self.resblock6(x)\n",
    "        x = self.resblock7(x)\n",
    "        x = self.resblock8(x)\n",
    "        x = self.resblock9(x)\n",
    "        x = self.resblock10(x)\n",
    "        x = self.resblock11(x)\n",
    "        x = self.resblock12(x)\n",
    "        x = self.resblock13(x)\n",
    "        x= self.resblock14(x)\n",
    "        #x= self.resblock15(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x) \n",
    "     \n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNetF()\n",
    "model=model.cuda()\n",
    "random_matrix = torch.rand(1, 3, 224, 224).cuda()\n",
    "print(model.forward(random_matrix).shape)\n",
    "summary(model,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity = 'relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def calculate_accuracy(y_pred, y): # calcualting the accuracy of the model\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device): # traing the model on with the images in iterator\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "   \n",
    "    model.train()\n",
    "   \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    lr_scheduler.step()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred= model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train loss per epoch =>  0 1.6570401862454232 train acc per epoch=>  0.3939058503988759\n",
      "val loss per epoch =>  1.4700418469272083 val acc per epoch => 0.4828916139240506 \n",
      "\n",
      "train loss per epoch =>  1 1.3315657127238905 train acc per epoch=>  0.5193014705882353\n",
      "val loss per epoch =>  1.212222799470153 val acc per epoch => 0.5584454113924051 \n",
      "\n",
      "train loss per epoch =>  2 1.1885081971697795 train acc per epoch=>  0.5725263747412835\n",
      "val loss per epoch =>  1.2227718543402757 val acc per epoch => 0.5773338607594937 \n",
      "\n",
      "train loss per epoch =>  3 1.0957887623925953 train acc per epoch=>  0.6083559782608695\n",
      "val loss per epoch =>  1.030723486520067 val acc per epoch => 0.6371637658227848 \n",
      "\n",
      "train loss per epoch =>  4 1.0216529168131407 train acc per epoch=>  0.6377997122457265\n",
      "val loss per epoch =>  1.030738276016863 val acc per epoch => 0.6430973101265823 \n",
      "\n",
      "train loss per epoch =>  5 0.9688519939132358 train acc per epoch=>  0.6562619884605603\n",
      "val loss per epoch =>  0.8539348644546315 val acc per epoch => 0.700751582278481 \n",
      "\n",
      "train loss per epoch =>  6 0.9204818193260056 train acc per epoch=>  0.673861093380872\n",
      "val loss per epoch =>  0.9410954593103144 val acc per epoch => 0.672567246835443 \n",
      "\n",
      "train loss per epoch =>  7 0.8807847926683743 train acc per epoch=>  0.6878756394471659\n",
      "val loss per epoch =>  0.9859389904179151 val acc per epoch => 0.6753362341772152 \n",
      "\n",
      "train loss per epoch =>  8 0.8496718146002201 train acc per epoch=>  0.7008791559797418\n",
      "val loss per epoch =>  0.7733664158024366 val acc per epoch => 0.7254746835443038 \n",
      "\n",
      "train loss per epoch =>  9 0.8166850543083133 train acc per epoch=>  0.7126118926440969\n",
      "val loss per epoch =>  0.7896063093897663 val acc per epoch => 0.7279469936708861 \n",
      "\n",
      "train loss per epoch =>  10 0.7950870452634514 train acc per epoch=>  0.7202565537389282\n",
      "val loss per epoch =>  0.7808773909943013 val acc per epoch => 0.7263647151898734 \n",
      "\n",
      "train loss per epoch =>  11 0.7706704776915138 train acc per epoch=>  0.7311940537694165\n",
      "val loss per epoch =>  0.6799822864653189 val acc per epoch => 0.7628560126582279 \n",
      "\n",
      "train loss per epoch =>  12 0.752125296293927 train acc per epoch=>  0.7353140984654731\n",
      "val loss per epoch =>  0.7051283298413965 val acc per epoch => 0.7590981012658228 \n",
      "\n",
      "train loss per epoch =>  13 0.7329902022391024 train acc per epoch=>  0.7427070012787724\n",
      "val loss per epoch =>  0.6870272544365895 val acc per epoch => 0.7606803797468354 \n",
      "\n",
      "train loss per epoch =>  14 0.7150372782021838 train acc per epoch=>  0.7476062980454291\n",
      "val loss per epoch =>  0.6724355450913876 val acc per epoch => 0.7719541139240507 \n",
      "\n",
      "train loss per epoch =>  15 0.7001973130666387 train acc per epoch=>  0.7553668477955986\n",
      "val loss per epoch =>  0.7036668846878824 val acc per epoch => 0.7541534810126582 \n",
      "\n",
      "train loss per epoch =>  16 0.6895193554403837 train acc per epoch=>  0.7578244884605603\n",
      "val loss per epoch =>  0.6324564712711528 val acc per epoch => 0.780557753164557 \n",
      "\n",
      "train loss per epoch =>  17 0.670048160092605 train acc per epoch=>  0.7673313619230714\n",
      "val loss per epoch =>  0.6998910975607135 val acc per epoch => 0.7652294303797469 \n",
      "\n",
      "train loss per epoch =>  18 0.6542867348931939 train acc per epoch=>  0.7720268542504372\n",
      "val loss per epoch =>  0.6387717561631263 val acc per epoch => 0.7785799050632911 \n",
      "\n",
      "train loss per epoch =>  19 0.6444769238724428 train acc per epoch=>  0.772886029442253\n",
      "val loss per epoch =>  0.5878689032566699 val acc per epoch => 0.8004351265822784 \n",
      "\n",
      "train loss per epoch =>  20 0.6374122706977913 train acc per epoch=>  0.7766464194068519\n",
      "val loss per epoch =>  0.6072370545773567 val acc per epoch => 0.7880735759493671 \n",
      "\n",
      "train loss per epoch =>  21 0.6209162774750644 train acc per epoch=>  0.7820931906285493\n",
      "val loss per epoch =>  0.6128678163395652 val acc per epoch => 0.7977650316455697 \n",
      "\n",
      "train loss per epoch =>  22 0.6143417805814377 train acc per epoch=>  0.78434702685422\n",
      "val loss per epoch =>  0.6308335714702364 val acc per epoch => 0.7861946202531646 \n",
      "\n",
      "train loss per epoch =>  23 0.6033044233346534 train acc per epoch=>  0.7886069374316184\n",
      "val loss per epoch =>  0.664374029711832 val acc per epoch => 0.7756131329113924 \n",
      "\n",
      "train loss per epoch =>  24 0.5907462992326683 train acc per epoch=>  0.7924592391304348\n",
      "val loss per epoch =>  0.5956711108925976 val acc per epoch => 0.7924248417721519 \n",
      "\n",
      "train loss per epoch =>  25 0.5828745857529019 train acc per epoch=>  0.7948849105164218\n",
      "val loss per epoch =>  0.5926993832558016 val acc per epoch => 0.8034018987341772 \n",
      "\n",
      "train loss per epoch =>  26 0.5753800146415106 train acc per epoch=>  0.796807065186903\n",
      "val loss per epoch =>  0.6004723883882354 val acc per epoch => 0.7906447784810127 \n",
      "\n",
      "train loss per epoch =>  27 0.5684185868791302 train acc per epoch=>  0.8008671675801582\n",
      "val loss per epoch =>  0.5824342671828934 val acc per epoch => 0.7991495253164557 \n",
      "\n",
      "train loss per epoch =>  28 0.5574555630269258 train acc per epoch=>  0.8061500959993934\n",
      "val loss per epoch =>  0.5473615229129791 val acc per epoch => 0.8150712025316456 \n",
      "\n",
      "train loss per epoch =>  29 0.5486411534611831 train acc per epoch=>  0.8052030051760661\n",
      "val loss per epoch =>  0.5396991077857681 val acc per epoch => 0.8158623417721519 \n",
      "\n",
      "train loss per epoch =>  30 0.5424146005107314 train acc per epoch=>  0.8104219948849105\n",
      "val loss per epoch =>  0.5811781136295463 val acc per epoch => 0.8066653481012658 \n",
      "\n",
      "train loss per epoch =>  31 0.5380753293976455 train acc per epoch=>  0.8100223785166241\n",
      "val loss per epoch =>  0.5658626795946797 val acc per epoch => 0.8106210443037974 \n",
      "\n",
      "train loss per epoch =>  32 0.5258874148511521 train acc per epoch=>  0.8145780051150895\n",
      "val loss per epoch =>  0.5572984648656242 val acc per epoch => 0.8138844936708861 \n",
      "\n",
      "train loss per epoch =>  33 0.5205553434693905 train acc per epoch=>  0.815613011569928\n",
      "val loss per epoch =>  0.547829917337321 val acc per epoch => 0.8152689873417721 \n",
      "\n",
      "train loss per epoch =>  34 0.5172394195481029 train acc per epoch=>  0.817147538332683\n",
      "val loss per epoch =>  0.556750342061248 val acc per epoch => 0.8124011075949367 \n",
      "\n",
      "train loss per epoch =>  35 0.5131965654585368 train acc per epoch=>  0.8169437340458335\n",
      "val loss per epoch =>  0.5532041784328751 val acc per epoch => 0.8116099683544303 \n",
      "\n",
      "train loss per epoch =>  36 0.5028398145190285 train acc per epoch=>  0.8231297953964194\n",
      "val loss per epoch =>  0.5166501248184638 val acc per epoch => 0.8263449367088608 \n",
      "\n",
      "train loss per epoch =>  37 0.49341294565773985 train acc per epoch=>  0.826402653513662\n",
      "val loss per epoch =>  0.5616663800010199 val acc per epoch => 0.8139833860759493 \n",
      "\n",
      "train loss per epoch =>  38 0.493350015957947 train acc per epoch=>  0.8260869565217391\n",
      "val loss per epoch =>  0.5331377688842484 val acc per epoch => 0.8194224683544303 \n",
      "\n",
      "train loss per epoch =>  39 0.48305826281647546 train acc per epoch=>  0.8287204284497234\n",
      "val loss per epoch =>  0.5081603097010262 val acc per epoch => 0.8262460443037974 \n",
      "\n",
      "train loss per epoch =>  40 0.47911194896758974 train acc per epoch=>  0.8303228900255755\n",
      "val loss per epoch =>  0.5056404924090905 val acc per epoch => 0.8326740506329114 \n",
      "\n",
      "train loss per epoch =>  41 0.46908344073063885 train acc per epoch=>  0.8338115408902278\n",
      "val loss per epoch =>  0.5345399787154379 val acc per epoch => 0.8222903481012658 \n",
      "\n",
      "train loss per epoch =>  42 0.46536016479477554 train acc per epoch=>  0.8364729859944805\n",
      "val loss per epoch =>  0.5151801075361953 val acc per epoch => 0.8287183544303798 \n",
      "\n",
      "train loss per epoch =>  43 0.46000573816506757 train acc per epoch=>  0.837312180367882\n",
      "val loss per epoch =>  0.5046260734147663 val acc per epoch => 0.8309928797468354 \n",
      "\n",
      "train loss per epoch =>  44 0.4580827132057961 train acc per epoch=>  0.83867886837791\n",
      "val loss per epoch =>  0.5123688122139701 val acc per epoch => 0.8285205696202531 \n",
      "\n",
      "train loss per epoch =>  45 0.4518504767009364 train acc per epoch=>  0.8404132033248082\n",
      "val loss per epoch =>  0.5621855292893663 val acc per epoch => 0.817246835443038 \n",
      "\n",
      "train loss per epoch =>  46 0.4506854671041679 train acc per epoch=>  0.8400335677749361\n",
      "val loss per epoch =>  0.5291578682917583 val acc per epoch => 0.8267405063291139 \n",
      "\n",
      "train loss per epoch =>  47 0.4434562408558243 train acc per epoch=>  0.8421635229874145\n",
      "val loss per epoch =>  0.49365429372727115 val acc per epoch => 0.8336629746835443 \n",
      "\n",
      "train loss per epoch =>  48 0.43489554006120434 train acc per epoch=>  0.8471867007672634\n",
      "val loss per epoch =>  0.5162052647976936 val acc per epoch => 0.8284216772151899 \n",
      "\n",
      "train loss per epoch =>  49 0.428662099420567 train acc per epoch=>  0.8476382672329388\n",
      "val loss per epoch =>  0.5088747562486914 val acc per epoch => 0.8297072784810127 \n",
      "\n",
      "train loss per epoch =>  50 0.42744487508788437 train acc per epoch=>  0.8469669117647058\n",
      "val loss per epoch =>  0.5029555815684644 val acc per epoch => 0.8327729430379747 \n",
      "\n",
      "train loss per epoch =>  51 0.42337964692384084 train acc per epoch=>  0.8500839194373402\n",
      "val loss per epoch =>  0.5031798938407174 val acc per epoch => 0.8307950949367089 \n",
      "\n",
      "train loss per epoch =>  52 0.41864371002482637 train acc per epoch=>  0.8498041879795396\n",
      "val loss per epoch =>  0.5003175543078894 val acc per epoch => 0.834256329113924 \n",
      "\n",
      "train loss per epoch =>  53 0.4186275713431561 train acc per epoch=>  0.8506313938923808\n",
      "val loss per epoch =>  0.5315194974971723 val acc per epoch => 0.8275316455696202 \n",
      "\n",
      "train loss per epoch =>  54 0.40752206296871996 train acc per epoch=>  0.8563738811351455\n",
      "val loss per epoch =>  0.48350071756145624 val acc per epoch => 0.8423655063291139 \n",
      "\n",
      "train loss per epoch =>  55 0.400546894277758 train acc per epoch=>  0.856965313329721\n",
      "val loss per epoch =>  0.4759782522539549 val acc per epoch => 0.8434533227848101 \n",
      "\n",
      "train loss per epoch =>  56 0.39518963128252105 train acc per epoch=>  0.8588395141579611\n",
      "val loss per epoch =>  0.49857046106193637 val acc per epoch => 0.838310917721519 \n",
      "\n",
      "train loss per epoch =>  57 0.40004249839374173 train acc per epoch=>  0.8572450447875215\n",
      "val loss per epoch =>  0.5047168211091922 val acc per epoch => 0.8361352848101266 \n",
      "\n",
      "train loss per epoch =>  58 0.3939753041014342 train acc per epoch=>  0.8599064897393327\n",
      "val loss per epoch =>  0.5072024027003518 val acc per epoch => 0.8402887658227848 \n",
      "\n",
      "train loss per epoch =>  59 0.3834186647554188 train acc per epoch=>  0.8641863811351455\n",
      "val loss per epoch =>  0.5035006830209419 val acc per epoch => 0.8409810126582279 \n",
      "\n",
      "train loss per epoch =>  60 0.3853898751918617 train acc per epoch=>  0.8624600383936597\n",
      "val loss per epoch =>  0.5201370866992806 val acc per epoch => 0.8363330696202531 \n",
      "\n",
      "train loss per epoch =>  61 0.3794433173087552 train acc per epoch=>  0.8661325128791887\n",
      "val loss per epoch =>  0.4992191580277455 val acc per epoch => 0.8371242088607594 \n",
      "\n",
      "train loss per epoch =>  62 0.3752075408959328 train acc per epoch=>  0.8663123402449177\n",
      "val loss per epoch =>  0.48211860241769233 val acc per epoch => 0.8471123417721519 \n",
      "\n",
      "train loss per epoch =>  63 0.3696567894857558 train acc per epoch=>  0.8676550511813834\n",
      "val loss per epoch =>  0.5102605555630937 val acc per epoch => 0.8372231012658228 \n",
      "\n",
      "train loss per epoch =>  64 0.3657168138515004 train acc per epoch=>  0.8697650255754475\n",
      "val loss per epoch =>  0.4837795103652568 val acc per epoch => 0.8412776898734177 \n",
      "\n",
      "train loss per epoch =>  65 0.3613619638983246 train acc per epoch=>  0.8710078325722833\n",
      "val loss per epoch =>  0.5150542010234881 val acc per epoch => 0.8379153481012658 \n",
      "\n",
      "train loss per epoch =>  66 0.3656262262245578 train acc per epoch=>  0.8699528452990305\n",
      "val loss per epoch =>  0.48347562928743 val acc per epoch => 0.8438488924050633 \n",
      "\n",
      "train loss per epoch =>  67 0.35876194176161685 train acc per epoch=>  0.8711117327670612\n",
      "val loss per epoch =>  0.4968733614004111 val acc per epoch => 0.8457278481012658 \n",
      "\n",
      "train loss per epoch =>  68 0.348797975827361 train acc per epoch=>  0.8741008631713555\n",
      "val loss per epoch =>  0.49560986270632923 val acc per epoch => 0.8473101265822784 \n",
      "\n",
      "train loss per epoch =>  69 0.3491072420345243 train acc per epoch=>  0.8760909526549336\n",
      "val loss per epoch =>  0.49405900700182853 val acc per epoch => 0.8477056962025317 \n",
      "\n",
      "train loss per epoch =>  70 0.3496864977700021 train acc per epoch=>  0.8750119884605603\n",
      "val loss per epoch =>  0.49624206767052037 val acc per epoch => 0.844442246835443 \n",
      "\n",
      "train loss per epoch =>  71 0.3413052074897015 train acc per epoch=>  0.8793638107721763\n",
      "val loss per epoch =>  0.5081853781697117 val acc per epoch => 0.8401898734177216 \n",
      "\n",
      "train loss per epoch =>  72 0.3403533263050992 train acc per epoch=>  0.8780730499330994\n",
      "val loss per epoch =>  0.4895104871520513 val acc per epoch => 0.849189082278481 \n",
      "\n",
      "train loss per epoch =>  73 0.33068623067930225 train acc per epoch=>  0.8814418158872658\n",
      "val loss per epoch =>  0.511484877218174 val acc per epoch => 0.8451344936708861 \n",
      "\n",
      "train loss per epoch =>  74 0.33565740576942865 train acc per epoch=>  0.8782169117647058\n",
      "val loss per epoch =>  0.49542085769810257 val acc per epoch => 0.8426621835443038 \n",
      "\n",
      "train loss per epoch =>  75 0.3240743832819907 train acc per epoch=>  0.8845068734625111\n",
      "val loss per epoch =>  0.4769547996641714 val acc per epoch => 0.8488924050632911 \n",
      "\n",
      "train loss per epoch =>  76 0.32572155579200485 train acc per epoch=>  0.8825047953659312\n",
      "val loss per epoch =>  0.48179271817207336 val acc per epoch => 0.8470134493670886 \n",
      "\n",
      "train loss per epoch =>  77 0.3213944163392572 train acc per epoch=>  0.8848465473755546\n",
      "val loss per epoch =>  0.4894203047586393 val acc per epoch => 0.8517602848101266 \n",
      "\n",
      "train loss per epoch =>  78 0.3145162931564824 train acc per epoch=>  0.8873361573194909\n",
      "val loss per epoch =>  0.5030737504174437 val acc per epoch => 0.8442444620253164 \n",
      "\n",
      "train loss per epoch =>  79 0.3132849247444926 train acc per epoch=>  0.8887787723480283\n",
      "val loss per epoch =>  0.4856870793089082 val acc per epoch => 0.8524525316455697 \n",
      "\n",
      "train loss per epoch =>  80 0.308770868936768 train acc per epoch=>  0.8880394820666984\n",
      "val loss per epoch =>  0.5379293477987941 val acc per epoch => 0.8362341772151899 \n",
      "\n",
      "train loss per epoch =>  81 0.307038304788987 train acc per epoch=>  0.8895020780660917\n",
      "val loss per epoch =>  0.5224398118031176 val acc per epoch => 0.8415743670886076 \n",
      "\n",
      "train loss per epoch =>  82 0.30707930215179463 train acc per epoch=>  0.890888746894534\n",
      "val loss per epoch =>  0.5120271165159684 val acc per epoch => 0.8421677215189873 \n",
      "\n",
      "train loss per epoch =>  83 0.2987906834506013 train acc per epoch=>  0.8931226023017903\n",
      "val loss per epoch =>  0.5060328712946252 val acc per epoch => 0.8464200949367089 \n",
      "\n",
      "train loss per epoch =>  84 0.29754348832856664 train acc per epoch=>  0.893298433564813\n",
      "val loss per epoch =>  0.5087522317337084 val acc per epoch => 0.8480023734177216 \n",
      "\n",
      "train loss per epoch =>  85 0.29469361836495606 train acc per epoch=>  0.8944653133906977\n",
      "val loss per epoch =>  0.5023587466795233 val acc per epoch => 0.8502768987341772 \n",
      "\n",
      "train loss per epoch =>  86 0.2911569881241035 train acc per epoch=>  0.8957560742297745\n",
      "val loss per epoch =>  0.519706759648987 val acc per epoch => 0.8482990506329114 \n",
      "\n",
      "train loss per epoch =>  87 0.2906737839017073 train acc per epoch=>  0.8959558824139178\n",
      "val loss per epoch =>  0.5072826969472668 val acc per epoch => 0.8504746835443038 \n",
      "\n",
      "train loss per epoch =>  88 0.285081998295034 train acc per epoch=>  0.8975023977896747\n",
      "val loss per epoch =>  0.5022750745845747 val acc per epoch => 0.8496835443037974 \n",
      "\n",
      "train loss per epoch =>  89 0.2823299967571902 train acc per epoch=>  0.900115888746803\n",
      "val loss per epoch =>  0.507639398303213 val acc per epoch => 0.8504746835443038 \n",
      "\n",
      "train loss per epoch =>  90 0.27905337078034725 train acc per epoch=>  0.900371643283483\n",
      "val loss per epoch =>  0.5060790945080262 val acc per epoch => 0.850870253164557 \n",
      "\n",
      "train loss per epoch =>  91 0.2762093156423715 train acc per epoch=>  0.9015465153147803\n",
      "val loss per epoch =>  0.4917612232362168 val acc per epoch => 0.8531447784810127 \n",
      "\n",
      "train loss per epoch =>  92 0.2723797194640655 train acc per epoch=>  0.9027413683169333\n",
      "val loss per epoch =>  0.49959391053718855 val acc per epoch => 0.8543314873417721 \n",
      "\n",
      "train loss per epoch =>  93 0.2712769621168561 train acc per epoch=>  0.903093030690537\n",
      "val loss per epoch =>  0.5152637728407413 val acc per epoch => 0.8501780063291139 \n",
      "\n",
      "train loss per epoch =>  94 0.26527846612207723 train acc per epoch=>  0.9052509590792839\n",
      "val loss per epoch =>  0.5113860097112535 val acc per epoch => 0.8513647151898734 \n",
      "\n",
      "train loss per epoch =>  95 0.27063858154637127 train acc per epoch=>  0.9019621163987748\n",
      "val loss per epoch =>  0.5081123913390727 val acc per epoch => 0.8496835443037974 \n",
      "\n",
      "train loss per epoch =>  96 0.26427244250198156 train acc per epoch=>  0.9049312659846548\n",
      "val loss per epoch =>  0.49891811307472517 val acc per epoch => 0.8559137658227848 \n",
      "\n",
      "train loss per epoch =>  97 0.25947998999558447 train acc per epoch=>  0.9061381074473681\n",
      "val loss per epoch =>  0.5183104257794875 val acc per epoch => 0.8518591772151899 \n",
      "\n",
      "train loss per epoch =>  98 0.25462834794274375 train acc per epoch=>  0.9091112532883959\n",
      "val loss per epoch =>  0.5101744453363781 val acc per epoch => 0.8509691455696202 \n",
      "\n",
      "train loss per epoch =>  99 0.25751364968545604 train acc per epoch=>  0.9060342072525902\n",
      "val loss per epoch =>  0.5419663398326198 val acc per epoch => 0.8479034810126582 \n",
      "\n",
      "train loss per epoch =>  100 0.24985748584694265 train acc per epoch=>  0.9088075447570333\n",
      "val loss per epoch =>  0.5070395665832713 val acc per epoch => 0.8564082278481012 \n",
      "\n",
      "train loss per epoch =>  101 0.24760828830320816 train acc per epoch=>  0.9090712916515672\n",
      "val loss per epoch =>  0.5018834492451028 val acc per epoch => 0.8534414556962026 \n",
      "\n",
      "train loss per epoch =>  102 0.24440560299341027 train acc per epoch=>  0.9123361572585142\n",
      "val loss per epoch =>  0.5069536638410785 val acc per epoch => 0.8557159810126582 \n",
      "\n",
      "train loss per epoch =>  103 0.24441529414080598 train acc per epoch=>  0.9107856457800512\n",
      "val loss per epoch =>  0.5161548113521142 val acc per epoch => 0.8527492088607594 \n",
      "\n",
      "train loss per epoch =>  104 0.23936363665953928 train acc per epoch=>  0.9130634590792839\n",
      "val loss per epoch =>  0.5160538512694685 val acc per epoch => 0.853935917721519 \n",
      "\n",
      "train loss per epoch =>  105 0.23667909467921538 train acc per epoch=>  0.9145140664656753\n",
      "val loss per epoch =>  0.5253684792337538 val acc per epoch => 0.8554193037974683 \n",
      "\n",
      "train loss per epoch =>  106 0.22765099617373913 train acc per epoch=>  0.918330402782811\n",
      "val loss per epoch =>  0.5204285632205915 val acc per epoch => 0.8555181962025317 \n",
      "\n",
      "train loss per epoch =>  107 0.233966728134076 train acc per epoch=>  0.9163722825782074\n",
      "val loss per epoch =>  0.5244838602935211 val acc per epoch => 0.8573971518987342 \n",
      "\n",
      "train loss per epoch =>  108 0.22919069268666875 train acc per epoch=>  0.918150575417082\n",
      "val loss per epoch =>  0.5245229349106173 val acc per epoch => 0.8561115506329114 \n",
      "\n",
      "train loss per epoch =>  109 0.22470277650734347 train acc per epoch=>  0.9194613172270149\n",
      "val loss per epoch =>  0.533584927833533 val acc per epoch => 0.8559137658227848 \n",
      "\n",
      "train loss per epoch =>  110 0.22497160894715268 train acc per epoch=>  0.9190217392218997\n",
      "val loss per epoch =>  0.5278267171941226 val acc per epoch => 0.8554193037974683 \n",
      "\n",
      "train loss per epoch =>  111 0.2246964208953216 train acc per epoch=>  0.91842231466947\n",
      "val loss per epoch =>  0.52343272521526 val acc per epoch => 0.8573971518987342 \n",
      "\n",
      "train loss per epoch =>  112 0.21741666480936966 train acc per epoch=>  0.9221667199183607\n",
      "val loss per epoch =>  0.5248016207655773 val acc per epoch => 0.8583860759493671 \n",
      "\n",
      "train loss per epoch =>  113 0.2160320942435423 train acc per epoch=>  0.9219709079893653\n",
      "val loss per epoch =>  0.5555082276652131 val acc per epoch => 0.8545292721518988 \n",
      "\n",
      "train loss per epoch =>  114 0.21619712010673856 train acc per epoch=>  0.9229140025575447\n",
      "val loss per epoch =>  0.5117704332629337 val acc per epoch => 0.857001582278481 \n",
      "\n",
      "train loss per epoch =>  115 0.2112064348995838 train acc per epoch=>  0.9225983057180633\n",
      "val loss per epoch =>  0.5220511893305597 val acc per epoch => 0.8577927215189873 \n",
      "\n",
      "train loss per epoch =>  116 0.20852109119105522 train acc per epoch=>  0.9238890665571403\n",
      "val loss per epoch =>  0.5317791145813616 val acc per epoch => 0.857693829113924 \n",
      "\n",
      "train loss per epoch =>  117 0.2054238035093488 train acc per epoch=>  0.9261269182195444\n",
      "val loss per epoch =>  0.5374675811846045 val acc per epoch => 0.8543314873417721 \n",
      "\n",
      "train loss per epoch =>  118 0.20364911509368122 train acc per epoch=>  0.9262507992327366\n",
      "val loss per epoch =>  0.5281510130514072 val acc per epoch => 0.8581882911392406 \n",
      "\n",
      "train loss per epoch =>  119 0.20333747304690158 train acc per epoch=>  0.9279531650531018\n",
      "val loss per epoch =>  0.5358802827098702 val acc per epoch => 0.8566060126582279 \n",
      "\n",
      "train loss per epoch =>  120 0.20031975255445447 train acc per epoch=>  0.926898177779849\n",
      "val loss per epoch =>  0.5310479225237158 val acc per epoch => 0.8598694620253164 \n",
      "\n",
      "train loss per epoch =>  121 0.195268879708884 train acc per epoch=>  0.9294597186395884\n",
      "val loss per epoch =>  0.5518773034026351 val acc per epoch => 0.8544303797468354 \n",
      "\n",
      "train loss per epoch =>  122 0.1938602640615095 train acc per epoch=>  0.9305266943734015\n",
      "val loss per epoch =>  0.5424608205315433 val acc per epoch => 0.8556170886075949 \n",
      "\n",
      "train loss per epoch =>  123 0.1931432810090387 train acc per epoch=>  0.9296675191815856\n",
      "val loss per epoch =>  0.5326921000510831 val acc per epoch => 0.859375 \n",
      "\n",
      "train loss per epoch =>  124 0.189413467179174 train acc per epoch=>  0.9312140345573425\n",
      "val loss per epoch =>  0.5491480070956146 val acc per epoch => 0.8537381329113924 \n",
      "\n",
      "train loss per epoch =>  125 0.18610517661589795 train acc per epoch=>  0.9320891944648665\n",
      "val loss per epoch =>  0.5496730513965027 val acc per epoch => 0.8557159810126582 \n",
      "\n",
      "train loss per epoch =>  126 0.1872054436589446 train acc per epoch=>  0.9325407609305418\n",
      "val loss per epoch =>  0.546246367164805 val acc per epoch => 0.8597705696202531 \n",
      "\n",
      "train loss per epoch =>  127 0.186099387305167 train acc per epoch=>  0.9337635869565217\n",
      "val loss per epoch =>  0.5451897856178163 val acc per epoch => 0.857693829113924 \n",
      "\n",
      "train loss per epoch =>  128 0.1828218915540239 train acc per epoch=>  0.9348785166850175\n",
      "val loss per epoch =>  0.5488487450005133 val acc per epoch => 0.8568037974683544 \n",
      "\n",
      "train loss per epoch =>  129 0.18337503756822832 train acc per epoch=>  0.9345628196930946\n",
      "val loss per epoch =>  0.546042753737184 val acc per epoch => 0.8562104430379747 \n",
      "\n",
      "train loss per epoch =>  130 0.18148836057128198 train acc per epoch=>  0.9348585358666032\n",
      "val loss per epoch =>  0.5411864664358429 val acc per epoch => 0.8601661392405063 \n",
      "\n",
      "train loss per epoch =>  131 0.1758998667683138 train acc per epoch=>  0.9355059144137156\n",
      "val loss per epoch =>  0.5580653819856765 val acc per epoch => 0.8569026898734177 \n",
      "\n",
      "train loss per epoch =>  132 0.17659653622247373 train acc per epoch=>  0.9362132352636293\n",
      "val loss per epoch =>  0.5616431760637066 val acc per epoch => 0.8568037974683544 \n",
      "\n",
      "train loss per epoch =>  133 0.1728751720941585 train acc per epoch=>  0.9371163683474216\n",
      "val loss per epoch =>  0.5630358329302148 val acc per epoch => 0.8573971518987342 \n",
      "\n",
      "train loss per epoch =>  134 0.17396162194021217 train acc per epoch=>  0.936752717360816\n",
      "val loss per epoch =>  0.5474051655847815 val acc per epoch => 0.8585838607594937 \n",
      "\n",
      "train loss per epoch =>  135 0.16837944059878054 train acc per epoch=>  0.938610933473348\n",
      "val loss per epoch =>  0.543194354334964 val acc per epoch => 0.8594738924050633 \n",
      "\n",
      "train loss per epoch =>  136 0.16367755395829525 train acc per epoch=>  0.9412284206856242\n",
      "val loss per epoch =>  0.5715234232476994 val acc per epoch => 0.8552215189873418 \n",
      "\n",
      "train loss per epoch =>  137 0.16491965501738326 train acc per epoch=>  0.9408647698514602\n",
      "val loss per epoch =>  0.5550297164841543 val acc per epoch => 0.861056170886076 \n",
      "\n",
      "train loss per epoch =>  138 0.16645612643883967 train acc per epoch=>  0.9400495523991792\n",
      "val loss per epoch =>  0.5518552940103072 val acc per epoch => 0.858682753164557 \n",
      "\n",
      "train loss per epoch =>  139 0.1594138065700793 train acc per epoch=>  0.9422474424247547\n",
      "val loss per epoch =>  0.5599272024782398 val acc per epoch => 0.8583860759493671 \n",
      "\n",
      "train loss per epoch =>  140 0.1600547290366629 train acc per epoch=>  0.9413602942091119\n",
      "val loss per epoch =>  0.5780252921807615 val acc per epoch => 0.8571993670886076 \n",
      "\n",
      "train loss per epoch =>  141 0.15934520332938265 train acc per epoch=>  0.9419916880405163\n",
      "val loss per epoch =>  0.5596956027836739 val acc per epoch => 0.8609572784810127 \n",
      "\n",
      "train loss per epoch =>  142 0.154232230599579 train acc per epoch=>  0.944896899068447\n",
      "val loss per epoch =>  0.5586483440821683 val acc per epoch => 0.860067246835443 \n",
      "\n",
      "train loss per epoch =>  143 0.15008150638483675 train acc per epoch=>  0.9466072570942247\n",
      "val loss per epoch =>  0.5650441693731502 val acc per epoch => 0.8588805379746836 \n",
      "\n",
      "train loss per epoch =>  144 0.15525597661657406 train acc per epoch=>  0.9434223146084935\n",
      "val loss per epoch =>  0.5642094646073594 val acc per epoch => 0.8598694620253164 \n",
      "\n",
      "train loss per epoch =>  145 0.1495676112868597 train acc per epoch=>  0.9452965154367334\n",
      "val loss per epoch =>  0.560691281775885 val acc per epoch => 0.8594738924050633 \n",
      "\n",
      "train loss per epoch =>  146 0.14946041323835282 train acc per epoch=>  0.9462915601023018\n",
      "val loss per epoch =>  0.559872950556912 val acc per epoch => 0.8604628164556962 \n",
      "\n",
      "train loss per epoch =>  147 0.15273397361569088 train acc per epoch=>  0.9450527493606138\n",
      "val loss per epoch =>  0.5565308653101136 val acc per epoch => 0.8598694620253164 \n",
      "\n",
      "train loss per epoch =>  148 0.14519702207744883 train acc per epoch=>  0.9484215153147803\n",
      "val loss per epoch =>  0.5737985574369189 val acc per epoch => 0.8589794303797469 \n",
      "\n",
      "train loss per epoch =>  149 0.14612727430279907 train acc per epoch=>  0.946747122823125\n",
      "val loss per epoch =>  0.5689426709579516 val acc per epoch => 0.860067246835443 \n",
      "\n",
      "train loss per epoch =>  150 0.14171153127842243 train acc per epoch=>  0.9491288363171355\n",
      "val loss per epoch =>  0.5715540411728847 val acc per epoch => 0.8608583860759493 \n",
      "\n",
      "train loss per epoch =>  151 0.14549132744255272 train acc per epoch=>  0.947746163743841\n",
      "val loss per epoch =>  0.5592186722574355 val acc per epoch => 0.8628362341772152 \n",
      "\n",
      "train loss per epoch =>  152 0.13904302188045228 train acc per epoch=>  0.9498721228536132\n",
      "val loss per epoch =>  0.5713565044010742 val acc per epoch => 0.860067246835443 \n",
      "\n",
      "train loss per epoch =>  153 0.14258028055205368 train acc per epoch=>  0.9494325448484982\n",
      "val loss per epoch =>  0.5751729456684257 val acc per epoch => 0.861056170886076 \n",
      "\n",
      "train loss per epoch =>  154 0.1369545750529565 train acc per epoch=>  0.9509830563269612\n",
      "val loss per epoch =>  0.5748631418505802 val acc per epoch => 0.8612539556962026 \n",
      "\n",
      "train loss per epoch =>  155 0.13515015339950467 train acc per epoch=>  0.9517782928083863\n",
      "val loss per epoch =>  0.5772803757764116 val acc per epoch => 0.8587816455696202 \n",
      "\n",
      "train loss per epoch =>  156 0.1402062195188859 train acc per epoch=>  0.9494045716722298\n",
      "val loss per epoch =>  0.5802339334276658 val acc per epoch => 0.8598694620253164 \n",
      "\n",
      "train loss per epoch =>  157 0.13702721776597945 train acc per epoch=>  0.950707320971867\n",
      "val loss per epoch =>  0.5774171329751799 val acc per epoch => 0.8585838607594937 \n",
      "\n",
      "train loss per epoch =>  158 0.13368065241733781 train acc per epoch=>  0.9515185421690002\n",
      "val loss per epoch =>  0.5756862880308417 val acc per epoch => 0.8582871835443038 \n",
      "\n",
      "train loss per epoch =>  159 0.13365966487494882 train acc per epoch=>  0.9522578324503301\n",
      "val loss per epoch =>  0.5880635927749586 val acc per epoch => 0.8572982594936709 \n",
      "\n",
      "train loss per epoch =>  160 0.12929049915517382 train acc per epoch=>  0.9541959718365194\n",
      "val loss per epoch =>  0.579617630831803 val acc per epoch => 0.8597705696202531 \n",
      "\n",
      "train loss per epoch =>  161 0.12946621742089995 train acc per epoch=>  0.954355818383834\n",
      "val loss per epoch =>  0.5800859879089307 val acc per epoch => 0.8581882911392406 \n",
      "\n",
      "train loss per epoch =>  162 0.1336666650288855 train acc per epoch=>  0.9515425192425623\n",
      "val loss per epoch =>  0.5771311868595171 val acc per epoch => 0.8594738924050633 \n",
      "\n",
      "train loss per epoch =>  163 0.1265335304429159 train acc per epoch=>  0.9552389706492119\n",
      "val loss per epoch =>  0.5837031365195408 val acc per epoch => 0.8577927215189873 \n",
      "\n",
      "train loss per epoch =>  164 0.12988442215887483 train acc per epoch=>  0.9540241368286445\n",
      "val loss per epoch =>  0.5789290809933143 val acc per epoch => 0.8622428797468354 \n",
      "\n",
      "train loss per epoch =>  165 0.1300138615624374 train acc per epoch=>  0.9538762787418902\n",
      "val loss per epoch =>  0.5880246901813941 val acc per epoch => 0.8599683544303798 \n",
      "\n",
      "train loss per epoch =>  166 0.12809405735958262 train acc per epoch=>  0.9542279412679355\n",
      "val loss per epoch =>  0.5801745034471343 val acc per epoch => 0.8602650316455697 \n",
      "\n",
      "train loss per epoch =>  167 0.12619774216009527 train acc per epoch=>  0.9538243286445013\n",
      "val loss per epoch =>  0.5853223566767536 val acc per epoch => 0.8602650316455697 \n",
      "\n",
      "train loss per epoch =>  168 0.12685890578667222 train acc per epoch=>  0.9546035805626598\n",
      "val loss per epoch =>  0.5851997472817385 val acc per epoch => 0.8601661392405063 \n",
      "\n",
      "train loss per epoch =>  169 0.12632517266989973 train acc per epoch=>  0.9537044437340153\n",
      "val loss per epoch =>  0.588091860089121 val acc per epoch => 0.8595727848101266 \n",
      "\n",
      "train loss per epoch =>  170 0.12424594942299301 train acc per epoch=>  0.9561660806541248\n",
      "val loss per epoch =>  0.5765820756743226 val acc per epoch => 0.8609572784810127 \n",
      "\n",
      "train loss per epoch =>  171 0.12058653071751375 train acc per epoch=>  0.956977301851258\n",
      "val loss per epoch =>  0.5822148696531223 val acc per epoch => 0.8589794303797469 \n",
      "\n",
      "train loss per epoch =>  172 0.11964339609531795 train acc per epoch=>  0.9579883312325344\n",
      "val loss per epoch =>  0.5898235157320771 val acc per epoch => 0.8605617088607594 \n",
      "\n",
      "train loss per epoch =>  173 0.11939846311726839 train acc per epoch=>  0.9575047954878844\n",
      "val loss per epoch =>  0.5859696352029149 val acc per epoch => 0.8591772151898734 \n",
      "\n",
      "train loss per epoch =>  174 0.12342615882911341 train acc per epoch=>  0.9550871164597514\n",
      "val loss per epoch =>  0.5860259959214851 val acc per epoch => 0.8575949367088608 \n",
      "\n",
      "train loss per epoch =>  175 0.11946902587018965 train acc per epoch=>  0.9571211636828645\n",
      "val loss per epoch =>  0.5883316854132882 val acc per epoch => 0.8603639240506329 \n",
      "\n",
      "train loss per epoch =>  176 0.12163950258013233 train acc per epoch=>  0.9565736892278237\n",
      "val loss per epoch =>  0.5851373197157171 val acc per epoch => 0.8611550632911392 \n",
      "\n",
      "train loss per epoch =>  177 0.1188721592106935 train acc per epoch=>  0.9573249681221555\n",
      "val loss per epoch =>  0.5756279279159594 val acc per epoch => 0.8623417721518988 \n",
      "\n",
      "train loss per epoch =>  178 0.1190625559205137 train acc per epoch=>  0.95845188615877\n",
      "val loss per epoch =>  0.5802679080751878 val acc per epoch => 0.8631329113924051 \n",
      "\n",
      "train loss per epoch =>  179 0.11961352759424378 train acc per epoch=>  0.9568853901170403\n",
      "val loss per epoch =>  0.5871695589415634 val acc per epoch => 0.8607594936708861 \n",
      "\n",
      "train loss per epoch =>  180 0.11777926519360689 train acc per epoch=>  0.9580522697904835\n",
      "val loss per epoch =>  0.5827749043325835 val acc per epoch => 0.8602650316455697 \n",
      "\n",
      "train loss per epoch =>  181 0.11766979648062335 train acc per epoch=>  0.9576766304957592\n",
      "val loss per epoch =>  0.5852705010130436 val acc per epoch => 0.8606606012658228 \n",
      "\n",
      "train loss per epoch =>  182 0.11639725290181692 train acc per epoch=>  0.9594549233346339\n",
      "val loss per epoch =>  0.5863408450084396 val acc per epoch => 0.8611550632911392 \n",
      "\n",
      "train loss per epoch =>  183 0.11950461794634151 train acc per epoch=>  0.957960358056266\n",
      "val loss per epoch =>  0.583172392618807 val acc per epoch => 0.8615506329113924 \n",
      "\n",
      "train loss per epoch =>  184 0.11629909009236813 train acc per epoch=>  0.9572290601327901\n",
      "val loss per epoch =>  0.5835986231701283 val acc per epoch => 0.8603639240506329 \n",
      "\n",
      "train loss per epoch =>  185 0.11806014965257376 train acc per epoch=>  0.958571771069256\n",
      "val loss per epoch =>  0.5877791971345491 val acc per epoch => 0.8596716772151899 \n",
      "\n",
      "train loss per epoch =>  186 0.11753973109490426 train acc per epoch=>  0.9584119245219413\n",
      "val loss per epoch =>  0.580168879107584 val acc per epoch => 0.8615506329113924 \n",
      "\n",
      "train loss per epoch =>  187 0.1139605146882784 train acc per epoch=>  0.9594229540556592\n",
      "val loss per epoch =>  0.5848957111563864 val acc per epoch => 0.8607594936708861 \n",
      "\n",
      "train loss per epoch =>  188 0.1141297401255354 train acc per epoch=>  0.9599424553344317\n",
      "val loss per epoch =>  0.58781421448611 val acc per epoch => 0.8603639240506329 \n",
      "\n",
      "train loss per epoch =>  189 0.11580517121097621 train acc per epoch=>  0.958519820971867\n",
      "val loss per epoch =>  0.5872076900699471 val acc per epoch => 0.8609572784810127 \n",
      "\n",
      "train loss per epoch =>  190 0.11393860265460161 train acc per epoch=>  0.9593470268847083\n",
      "val loss per epoch =>  0.587003618478775 val acc per epoch => 0.8619462025316456 \n",
      "\n",
      "train loss per epoch =>  191 0.1166629151767477 train acc per epoch=>  0.958148177779849\n",
      "val loss per epoch =>  0.5835896228687673 val acc per epoch => 0.8614517405063291 \n",
      "\n",
      "train loss per epoch =>  192 0.11498165122040398 train acc per epoch=>  0.9595588235294118\n",
      "val loss per epoch =>  0.5888861312141901 val acc per epoch => 0.8615506329113924 \n",
      "\n",
      "train loss per epoch =>  193 0.1145628875459704 train acc per epoch=>  0.9589913682559567\n",
      "val loss per epoch =>  0.587923576182957 val acc per epoch => 0.8613528481012658 \n",
      "\n",
      "train loss per epoch =>  194 0.11526836828350107 train acc per epoch=>  0.9587515984349848\n",
      "val loss per epoch =>  0.584627314836164 val acc per epoch => 0.8612539556962026 \n",
      "\n",
      "train loss per epoch =>  195 0.11411417699645242 train acc per epoch=>  0.9594349425162196\n",
      "val loss per epoch =>  0.5877180099487305 val acc per epoch => 0.8599683544303798 \n",
      "\n",
      "train loss per epoch =>  196 0.11621245760899371 train acc per epoch=>  0.9582001278772379\n",
      "val loss per epoch =>  0.5840652800059016 val acc per epoch => 0.8604628164556962 \n",
      "\n",
      "train loss per epoch =>  197 0.11461627640573264 train acc per epoch=>  0.9598225704239457\n",
      "val loss per epoch =>  0.5871339346034617 val acc per epoch => 0.8606606012658228 \n",
      "\n",
      "train loss per epoch =>  198 0.11688964172740422 train acc per epoch=>  0.9575767264036876\n",
      "val loss per epoch =>  0.5858910483650014 val acc per epoch => 0.8618473101265823 \n",
      "\n",
      "train loss per epoch =>  199 0.11118612250270289 train acc per epoch=>  0.959259111253197\n",
      "val loss per epoch =>  0.5907019105138658 val acc per epoch => 0.8621439873417721 \n",
      "\n",
      "CPU times: user 23min 3s, sys: 5min 10s, total: 28min 13s\n",
      "Wall time: 33min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomCrop(size=32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(20),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "     ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True,transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "                            ]))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    \n",
    "model =ResNetF()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, 200)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "  \n",
    "\n",
    "loss =10\n",
    "train_loss_history=[]\n",
    "train_acc_history=[]\n",
    "test_loss_history=[]\n",
    "test_acc_history=[]\n",
    "EPOCHS=200\n",
    "for i in range(EPOCHS):\n",
    "    # using train iterator\n",
    "    train_loss , epoch_acc = train(model,trainloader, optimizer, criterion, device=device)\n",
    "    print(\"train loss per epoch => \", i, train_loss, \"train acc per epoch=> \" , epoch_acc)\n",
    "    \n",
    "    epoch_loss , epoch_valid_acc = evaluate(model, testloader, criterion, device)\n",
    "    print(\"val loss per epoch => \", epoch_loss , \"val acc per epoch =>\",epoch_valid_acc,\"\\n\")\n",
    "        \n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "    test_loss_history.append(epoch_loss)\n",
    "    test_acc_history.append(epoch_valid_acc)\n",
    "    \n",
    "    if epoch_loss<loss:\n",
    "        torch.save(model,\"./res_512_d.pt\")\n",
    "        loss= epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631329113924051"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./train_acc_history.txt\",train_acc_history)\n",
    "np.savetxt(\"./train_loss_history.txt\",train_loss_history)\n",
    "np.savetxt(\"./test_acc_history.txt\",test_acc_history)\n",
    "np.savetxt(\"./test_loss_history.txt\",test_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
